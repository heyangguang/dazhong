# è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿæµ‹è¯•è§„èŒƒå’Œè®¡åˆ’æ–‡æ¡£

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** 1.0  
**ç¼–å†™æ—¥æœŸï¼š** 2025å¹´7æœˆ23æ—¥  
**ç¼–å†™äººå‘˜ï¼š** æµ‹è¯•ç»ç†  
**å®¡æ ¸äººå‘˜ï¼š** è´¨é‡ä¿è¯æ€»ç›‘  

## 1. å¼•è¨€

### 1.1 ç¼–å†™ç›®çš„
æœ¬æ–‡æ¡£è§„å®šäº†è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿçš„æµ‹è¯•ç­–ç•¥ã€æµ‹è¯•è§„èŒƒã€æµ‹è¯•è®¡åˆ’å’Œè´¨é‡ä¿è¯æ ‡å‡†ï¼Œä¸ºæµ‹è¯•æ´»åŠ¨æä¾›å…¨é¢æŒ‡å¯¼ï¼Œç¡®ä¿ç³»ç»Ÿè´¨é‡ç¬¦åˆè¦æ±‚ã€‚

### 1.2 æµ‹è¯•ç›®æ ‡
- **åŠŸèƒ½éªŒè¯**: ç¡®ä¿æ‰€æœ‰åŠŸèƒ½æŒ‰éœ€æ±‚æ­£ç¡®å®ç°
- **æ€§èƒ½ä¿è¯**: éªŒè¯ç³»ç»Ÿæ€§èƒ½æ»¡è¶³éåŠŸèƒ½éœ€æ±‚
- **å®‰å…¨æµ‹è¯•**: ç¡®ä¿ç³»ç»Ÿå…·å¤‡è¶³å¤Ÿçš„å®‰å…¨é˜²æŠ¤èƒ½åŠ›
- **å…¼å®¹æ€§**: éªŒè¯ç³»ç»Ÿåœ¨ä¸åŒç¯å¢ƒä¸‹çš„å…¼å®¹æ€§
- **å¯ç”¨æ€§**: ç¡®ä¿ç”¨æˆ·ç•Œé¢å‹å¥½ä¸”æ˜“äºä½¿ç”¨

### 1.3 æµ‹è¯•èŒƒå›´
- å‰ç«¯ç”¨æˆ·ç•Œé¢æµ‹è¯•
- åç«¯APIæ¥å£æµ‹è¯•
- æ•°æ®åº“åŠŸèƒ½æµ‹è¯•
- ç³»ç»Ÿé›†æˆæµ‹è¯•
- æ€§èƒ½å‹åŠ›æµ‹è¯•
- å®‰å…¨æ¸—é€æµ‹è¯•
- å…¼å®¹æ€§æµ‹è¯•

## 2. æµ‹è¯•ç­–ç•¥

### 2.1 æµ‹è¯•é‡‘å­—å¡”æ¨¡å‹

```mermaid
graph TB
    subgraph "æµ‹è¯•é‡‘å­—å¡”"
        A["æ‰‹å·¥æ¢ç´¢æµ‹è¯• - 5%<br/>ç”¨æˆ·ä½“éªŒã€è¾¹ç•Œæƒ…å†µ"]
        B["UIè‡ªåŠ¨åŒ–æµ‹è¯• - 15%<br/>ç«¯åˆ°ç«¯ä¸šåŠ¡æµç¨‹"]
        C["APIé›†æˆæµ‹è¯• - 30%<br/>æ¥å£åŠŸèƒ½ã€æ•°æ®æµ"]
        D["å•å…ƒæµ‹è¯• - 50%<br/>å‡½æ•°ã€æ–¹æ³•ã€ç»„ä»¶"]
    end
    
    D --> C
    C --> B
    B --> A
    
    style D fill:#28a745
    style C fill:#17a2b8
    style B fill:#ffc107
    style A fill:#dc3545
```

### 2.2 æµ‹è¯•åˆ†å±‚ç­–ç•¥

#### 2.2.1 ç¬¬ä¸€å±‚ï¼šå•å…ƒæµ‹è¯•
**ç›®æ ‡**: éªŒè¯å•ä¸ªå‡½æ•°ã€æ–¹æ³•ã€ç±»çš„æ­£ç¡®æ€§  
**è¦†ç›–ç‡è¦æ±‚**: â‰¥ 80%  
**æ‰§è¡Œé¢‘ç‡**: æ¯æ¬¡ä»£ç æäº¤  
**è´£ä»»äºº**: å¼€å‘å·¥ç¨‹å¸ˆ

**æµ‹è¯•èŒƒå›´**:
- æ•°æ®æ¨¡å‹æ–¹æ³•æµ‹è¯•
- å·¥å…·å‡½æ•°æµ‹è¯•
- ä¸šåŠ¡é€»è¾‘å•å…ƒæµ‹è¯•
- å‰ç«¯ç»„ä»¶å•å…ƒæµ‹è¯•

#### 2.2.2 ç¬¬äºŒå±‚ï¼šé›†æˆæµ‹è¯•
**ç›®æ ‡**: éªŒè¯æ¨¡å—é—´äº¤äº’å’Œæ•°æ®æµ  
**è¦†ç›–ç‡è¦æ±‚**: â‰¥ 60%  
**æ‰§è¡Œé¢‘ç‡**: æ¯æ—¥æ„å»º  
**è´£ä»»äºº**: å¼€å‘å·¥ç¨‹å¸ˆ + æµ‹è¯•å·¥ç¨‹å¸ˆ

**æµ‹è¯•èŒƒå›´**:
- APIæ¥å£æµ‹è¯•
- æ•°æ®åº“æ“ä½œæµ‹è¯•
- æœåŠ¡é—´é€šä¿¡æµ‹è¯•
- ç¬¬ä¸‰æ–¹é›†æˆæµ‹è¯•

#### 2.2.3 ç¬¬ä¸‰å±‚ï¼šç³»ç»Ÿæµ‹è¯•
**ç›®æ ‡**: éªŒè¯å®Œæ•´ç³»ç»ŸåŠŸèƒ½  
**è¦†ç›–ç‡è¦æ±‚**: â‰¥ 90%ä¸»è¦ç”¨ä¾‹  
**æ‰§è¡Œé¢‘ç‡**: æ¯æ¬¡å‘ç‰ˆå‰  
**è´£ä»»äºº**: æµ‹è¯•å·¥ç¨‹å¸ˆ

**æµ‹è¯•èŒƒå›´**:
- ç«¯åˆ°ç«¯ä¸šåŠ¡æµç¨‹
- ç”¨æˆ·ç•Œé¢æµ‹è¯•
- æ€§èƒ½æµ‹è¯•
- å®‰å…¨æµ‹è¯•

#### 2.2.4 ç¬¬å››å±‚ï¼šéªŒæ”¶æµ‹è¯•
**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿæ»¡è¶³ä¸šåŠ¡éœ€æ±‚  
**è¦†ç›–ç‡è¦æ±‚**: 100%éªŒæ”¶æ ‡å‡†  
**æ‰§è¡Œé¢‘ç‡**: å‘ç‰ˆå‰  
**è´£ä»»äºº**: äº§å“ç»ç† + ç”¨æˆ·ä»£è¡¨

**æµ‹è¯•èŒƒå›´**:
- ä¸šåŠ¡åœºæ™¯éªŒè¯
- ç”¨æˆ·ä½“éªŒæµ‹è¯•
- å…¼å®¹æ€§æµ‹è¯•

### 2.3 æµ‹è¯•ç¯å¢ƒç­–ç•¥

```mermaid
graph LR
    A[å¼€å‘ç¯å¢ƒ<br/>DEV] --> B[æµ‹è¯•ç¯å¢ƒ<br/>TEST]
    B --> C[é¢„å‘å¸ƒç¯å¢ƒ<br/>STAGING]
    C --> D[ç”Ÿäº§ç¯å¢ƒ<br/>PROD]
    
    subgraph "æµ‹è¯•æ´»åŠ¨"
        E[å•å…ƒæµ‹è¯•<br/>é›†æˆæµ‹è¯•]
        F[ç³»ç»Ÿæµ‹è¯•<br/>æ€§èƒ½æµ‹è¯•]
        G[éªŒæ”¶æµ‹è¯•<br/>å›å½’æµ‹è¯•]
        H[ç›‘æ§æµ‹è¯•<br/>æ•…éšœæ¼”ç»ƒ]
    end
    
    A -.-> E
    B -.-> F
    C -.-> G
    D -.-> H
```

## 3. æµ‹è¯•è§„èŒƒ

### 3.1 å•å…ƒæµ‹è¯•è§„èŒƒ

#### 3.1.1 æµ‹è¯•æ–‡ä»¶ç»“æ„

```python
# tests/unit/test_models.py
import pytest
from unittest.mock import Mock, patch
from datetime import datetime
from src.models import User, Evaluation, Activity

class TestUserModel:
    """ç”¨æˆ·æ¨¡å‹å•å…ƒæµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰ç½®æ¡ä»¶"""
        self.user_data = {
            'username': 'test_user',
            'password': 'test_password123'
        }
    
    def test_user_creation(self):
        """æµ‹è¯•ç”¨æˆ·åˆ›å»º"""
        user = User(**self.user_data)
        assert user.username == 'test_user'
        assert user.created_at is not None
    
    def test_password_hashing(self):
        """æµ‹è¯•å¯†ç å“ˆå¸ŒåŠŸèƒ½"""
        user = User(username='test_user')
        user.set_password('password123')
        
        # éªŒè¯å¯†ç ä¸ä»¥æ˜æ–‡å­˜å‚¨
        assert user.password_hash != 'password123'
        
        # éªŒè¯å¯†ç éªŒè¯åŠŸèƒ½
        assert user.check_password('password123') is True
        assert user.check_password('wrong_password') is False
    
    @pytest.mark.parametrize("username,expected", [
        ("valid_user", True),
        ("", False),
        ("u", False),  # å¤ªçŸ­
        ("a" * 81, False),  # å¤ªé•¿
        ("user-with-special-chars!", True),
        ("ç”¨æˆ·ä¸­æ–‡å", True)
    ])
    def test_username_validation(self, username, expected):
        """æµ‹è¯•ç”¨æˆ·åéªŒè¯ - å‚æ•°åŒ–æµ‹è¯•"""
        user = User(username=username)
        result = user.validate_username()
        assert result == expected
    
    def test_user_to_dict(self):
        """æµ‹è¯•ç”¨æˆ·å¯¹è±¡è½¬å­—å…¸"""
        user = User(**self.user_data)
        user.id = 1
        user.created_at = datetime(2025, 1, 1, 12, 0, 0)
        
        result = user.to_dict()
        
        expected_keys = ['id', 'username', 'created_at']
        assert all(key in result for key in expected_keys)
        assert result['username'] == 'test_user'
        assert 'password_hash' not in result  # æ•æ„Ÿä¿¡æ¯ä¸åº”è¯¥æš´éœ²

class TestEvaluationModel:
    """è¯„ä»·æ¨¡å‹å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def sample_evaluation(self):
        """è¯„ä»·æ•°æ®fixture"""
        return Evaluation(
            activity_id=1,
            vehicle_id=1,
            evaluator_id=1,
            category_id=1,
            score=8,
            content="æµ‹è¯•è¯„ä»·å†…å®¹"
        )
    
    def test_evaluation_creation(self, sample_evaluation):
        """æµ‹è¯•è¯„ä»·åˆ›å»º"""
        assert sample_evaluation.score == 8
        assert sample_evaluation.content == "æµ‹è¯•è¯„ä»·å†…å®¹"
        assert sample_evaluation.created_at is not None
    
    @pytest.mark.parametrize("score,expected", [
        (1, True),
        (5, True),
        (10, True),
        (0, False),
        (11, False),
        (-1, False),
        (None, False)
    ])
    def test_score_validation(self, score, expected):
        """æµ‹è¯•è¯„åˆ†éªŒè¯"""
        evaluation = Evaluation(score=score)
        assert evaluation.is_valid_score() == expected
    
    def test_evaluation_serialization(self, sample_evaluation):
        """æµ‹è¯•è¯„ä»·åºåˆ—åŒ–"""
        sample_evaluation.id = 1
        sample_evaluation.created_at = datetime(2025, 1, 1, 12, 0, 0)
        
        result = sample_evaluation.serialize()
        
        assert result['id'] == 1
        assert result['score'] == 8
        assert result['content'] == "æµ‹è¯•è¯„ä»·å†…å®¹"
        assert isinstance(result['created_at'], str)
    
    def test_content_length_validation(self):
        """æµ‹è¯•å†…å®¹é•¿åº¦éªŒè¯"""
        # æ­£å¸¸é•¿åº¦
        evaluation = Evaluation(content="æ­£å¸¸é•¿åº¦çš„è¯„ä»·å†…å®¹")
        assert evaluation.validate_content() is True
        
        # è¿‡é•¿å†…å®¹
        long_content = "a" * 10001  # è¶…è¿‡10000å­—ç¬¦
        evaluation = Evaluation(content=long_content)
        assert evaluation.validate_content() is False
    
    @patch('src.models.db.session')
    def test_save_evaluation(self, mock_session, sample_evaluation):
        """æµ‹è¯•è¯„ä»·ä¿å­˜ - Mockæ•°æ®åº“"""
        # æ‰§è¡Œä¿å­˜æ“ä½œ
        result = sample_evaluation.save()
        
        # éªŒè¯æ•°æ®åº“æ“ä½œè¢«è°ƒç”¨
        mock_session.add.assert_called_once_with(sample_evaluation)
        mock_session.commit.assert_called_once()
        
        # éªŒè¯è¿”å›ç»“æœ
        assert result is True
```

#### 3.1.2 æµ‹è¯•æ–­è¨€è§„èŒƒ

```python
class TestAssertionExamples:
    """æµ‹è¯•æ–­è¨€ç¤ºä¾‹"""
    
    def test_basic_assertions(self):
        """åŸºç¡€æ–­è¨€ç¤ºä¾‹"""
        # ç›¸ç­‰æ–­è¨€
        assert 2 + 2 == 4
        assert "hello" == "hello"
        
        # èº«ä»½æ–­è¨€
        assert True is True
        assert None is None
        
        # åŒ…å«æ–­è¨€
        assert "test" in "unittest"
        assert 1 in [1, 2, 3]
        
        # ç±»å‹æ–­è¨€
        assert isinstance("hello", str)
        assert isinstance([], list)
    
    def test_exception_assertions(self):
        """å¼‚å¸¸æ–­è¨€ç¤ºä¾‹"""
        # éªŒè¯æŠ›å‡ºç‰¹å®šå¼‚å¸¸
        with pytest.raises(ValueError):
            int("not_a_number")
        
        # éªŒè¯å¼‚å¸¸æ¶ˆæ¯
        with pytest.raises(ValueError, match="invalid literal"):
            int("not_a_number")
        
        # éªŒè¯å¼‚å¸¸ä¸è¢«æŠ›å‡º
        try:
            result = int("123")
            assert result == 123
        except ValueError:
            pytest.fail("ä¸åº”è¯¥æŠ›å‡ºValueErrorå¼‚å¸¸")
    
    def test_collection_assertions(self):
        """é›†åˆæ–­è¨€ç¤ºä¾‹"""
        data = [1, 2, 3, 4, 5]
        
        # é•¿åº¦æ–­è¨€
        assert len(data) == 5
        
        # ç©ºé›†åˆæ–­è¨€
        assert not []  # ç©ºåˆ—è¡¨
        assert bool([1, 2, 3])  # éç©ºåˆ—è¡¨
        
        # å­é›†æ–­è¨€
        assert set([1, 2]) <= set([1, 2, 3, 4])
        
        # æ’åºæ–­è¨€
        assert sorted(data) == data
    
    def test_approximate_assertions(self):
        """è¿‘ä¼¼å€¼æ–­è¨€ç¤ºä¾‹"""
        # æµ®ç‚¹æ•°æ¯”è¾ƒ
        assert 0.1 + 0.2 == pytest.approx(0.3)
        assert abs(0.1 + 0.2 - 0.3) < 1e-10
        
        # ç›¸å¯¹è¯¯å·®
        assert 100 == pytest.approx(99, rel=0.01)  # 1%ç›¸å¯¹è¯¯å·®
        
        # ç»å¯¹è¯¯å·®
        assert 1.0 == pytest.approx(1.1, abs=0.2)  # 0.2ç»å¯¹è¯¯å·®
```

### 3.2 é›†æˆæµ‹è¯•è§„èŒƒ

#### 3.2.1 APIæ¥å£æµ‹è¯•

```python
# tests/integration/test_api.py
import pytest
import json
from src import create_app, db
from src.models import User, Activity, Vehicle, Evaluator

@pytest.fixture
def app():
    """åˆ›å»ºæµ‹è¯•åº”ç”¨"""
    app = create_app('testing')
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///:memory:'
    app.config['TESTING'] = True
    
    with app.app_context():
        db.create_all()
        yield app
        db.drop_all()

@pytest.fixture
def client(app):
    """åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯"""
    return app.test_client()

@pytest.fixture
def auth_client(client):
    """åˆ›å»ºå·²è®¤è¯çš„æµ‹è¯•å®¢æˆ·ç«¯"""
    # åˆ›å»ºæµ‹è¯•ç”¨æˆ·
    user = User(username='admin')
    user.set_password('password123')
    db.session.add(user)
    db.session.commit()
    
    # æ‰§è¡Œç™»å½•
    login_data = {
        'username': 'admin',
        'password': 'password123'
    }
    response = client.post('/admin/login', data=login_data)
    assert response.status_code == 302  # é‡å®šå‘è¡¨ç¤ºç™»å½•æˆåŠŸ
    
    return client

@pytest.fixture
def sample_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    # åˆ›å»ºè½¦è¾†
    vehicle = Vehicle(name='æµ‹è¯•è½¦è¾†', model='TEST001')
    db.session.add(vehicle)
    
    # åˆ›å»ºæ´»åŠ¨
    activity = Activity(
        name='æµ‹è¯•æ´»åŠ¨',
        date='2025-01-15',
        vehicle_id=1
    )
    db.session.add(activity)
    
    # åˆ›å»ºè¯„ä»·äºº
    evaluator = Evaluator(
        name='æµ‹è¯•è¯„ä»·äºº',
        department='æµ‹è¯•éƒ¨é—¨'
    )
    db.session.add(evaluator)
    
    db.session.commit()
    
    return {
        'vehicle_id': vehicle.id,
        'activity_id': activity.id,
        'evaluator_id': evaluator.id
    }

class TestEvaluationAPI:
    """è¯„ä»·APIé›†æˆæµ‹è¯•"""
    
    def test_create_evaluation_success(self, auth_client, sample_data):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºè¯„ä»·"""
        evaluation_data = {
            'activity_id': sample_data['activity_id'],
            'vehicle_id': sample_data['vehicle_id'],
            'evaluator_id': sample_data['evaluator_id'],
            'category_id': 1,
            'score': 8,
            'content': 'è¿™æ˜¯ä¸€ä¸ªé›†æˆæµ‹è¯•è¯„ä»·'
        }
        
        response = auth_client.post(
            '/api/save_evaluation',
            data=json.dumps(evaluation_data),
            content_type='application/json'
        )
        
        assert response.status_code == 200
        
        response_data = json.loads(response.data)
        assert response_data['success'] is True
        assert 'evaluation_id' in response_data
        assert isinstance(response_data['evaluation_id'], int)
    
    def test_create_evaluation_validation_error(self, auth_client, sample_data):
        """æµ‹è¯•åˆ›å»ºè¯„ä»·æ—¶çš„éªŒè¯é”™è¯¯"""
        # ç¼ºå°‘å¿…éœ€å­—æ®µ
        incomplete_data = {
            'activity_id': sample_data['activity_id'],
            'vehicle_id': sample_data['vehicle_id'],
            # ç¼ºå°‘ evaluator_id, score, content
        }
        
        response = auth_client.post(
            '/api/save_evaluation',
            data=json.dumps(incomplete_data),
            content_type='application/json'
        )
        
        assert response.status_code == 400
        
        response_data = json.loads(response.data)
        assert response_data['success'] is False
        assert 'error' in response_data
    
    def test_invalid_score_range(self, auth_client, sample_data):
        """æµ‹è¯•æ— æ•ˆè¯„åˆ†èŒƒå›´"""
        invalid_scores = [0, 11, -1, None]
        
        for invalid_score in invalid_scores:
            evaluation_data = {
                'activity_id': sample_data['activity_id'],
                'vehicle_id': sample_data['vehicle_id'],
                'evaluator_id': sample_data['evaluator_id'],
                'score': invalid_score,
                'content': 'æµ‹è¯•å†…å®¹'
            }
            
            response = auth_client.post(
                '/api/save_evaluation',
                data=json.dumps(evaluation_data),
                content_type='application/json'
            )
            
            assert response.status_code == 400
            response_data = json.loads(response.data)
            assert 'è¯„åˆ†å¿…é¡»åœ¨1-10ä¹‹é—´' in response_data['error']
    
    def test_get_evaluations_list(self, auth_client, sample_data):
        """æµ‹è¯•è·å–è¯„ä»·åˆ—è¡¨"""
        # å…ˆåˆ›å»ºä¸€äº›æµ‹è¯•è¯„ä»·
        self._create_test_evaluations(sample_data)
        
        response = auth_client.get(
            f'/api/evaluations/{sample_data["activity_id"]}/{sample_data["vehicle_id"]}'
        )
        
        assert response.status_code == 200
        
        evaluations = json.loads(response.data)
        assert isinstance(evaluations, list)
        assert len(evaluations) > 0
        
        # éªŒè¯è¯„ä»·æ•°æ®ç»“æ„
        evaluation = evaluations[0]
        required_fields = ['id', 'score', 'content', 'evaluator_name', 'created_at']
        for field in required_fields:
            assert field in evaluation
    
    def test_get_evaluation_counts(self, auth_client, sample_data):
        """æµ‹è¯•è·å–è¯„ä»·ç»Ÿè®¡"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self._create_test_evaluations(sample_data)
        
        response = auth_client.get(
            f'/api/evaluation_counts/{sample_data["activity_id"]}/{sample_data["vehicle_id"]}'
        )
        
        assert response.status_code == 200
        
        counts = json.loads(response.data)
        assert isinstance(counts, dict)
        
        # éªŒè¯ç»Ÿè®¡æ•°æ®ç»“æ„
        for category_id, count in counts.items():
            assert isinstance(int(category_id), int)
            assert isinstance(count, int)
            assert count >= 0
    
    def test_unauthorized_access(self, client, sample_data):
        """æµ‹è¯•æœªæˆæƒè®¿é—®"""
        evaluation_data = {
            'activity_id': sample_data['activity_id'],
            'vehicle_id': sample_data['vehicle_id'],
            'evaluator_id': sample_data['evaluator_id'],
            'score': 8,
            'content': 'æµ‹è¯•å†…å®¹'
        }
        
        response = client.post(
            '/api/save_evaluation',
            data=json.dumps(evaluation_data),
            content_type='application/json'
        )
        
        # åº”è¯¥è¿”å›401æœªæˆæƒ
        assert response.status_code == 401
    
    def _create_test_evaluations(self, sample_data):
        """åˆ›å»ºæµ‹è¯•è¯„ä»·æ•°æ®"""
        from src.models import Evaluation, Category
        
        # åˆ›å»ºæµ‹è¯•åˆ†ç±»
        categories = [
            Category(name='åŠ¨åŠ›æ€»æˆ', name_en='Powertrain', order_num=1),
            Category(name='åº•ç›˜', name_en='Chassis', order_num=2),
            Category(name='å†…é¥°', name_en='Interior', order_num=3)
        ]
        
        for category in categories:
            db.session.add(category)
        db.session.commit()
        
        # åˆ›å»ºæµ‹è¯•è¯„ä»·
        evaluations = []
        for i, category in enumerate(categories, 1):
            evaluation = Evaluation(
                activity_id=sample_data['activity_id'],
                vehicle_id=sample_data['vehicle_id'],
                evaluator_id=sample_data['evaluator_id'],
                category_id=category.id,
                score=7 + i,  # 8, 9, 10
                content=f'æµ‹è¯•è¯„ä»·å†…å®¹ - {category.name}'
            )
            evaluations.append(evaluation)
        
        for evaluation in evaluations:
            db.session.add(evaluation)
        db.session.commit()
```

#### 3.2.2 æ•°æ®åº“é›†æˆæµ‹è¯•

```python
# tests/integration/test_database.py
import pytest
from datetime import datetime
from sqlalchemy.exc import IntegrityError
from src import db
from src.models import User, Activity, Vehicle, Evaluation, Evaluator

class TestDatabaseIntegration:
    """æ•°æ®åº“é›†æˆæµ‹è¯•"""
    
    def test_user_crud_operations(self):
        """æµ‹è¯•ç”¨æˆ·CRUDæ“ä½œ"""
        # Create
        user = User(username='test_user')
        user.set_password('password123')
        db.session.add(user)
        db.session.commit()
        
        assert user.id is not None
        
        # Read
        retrieved_user = User.query.filter_by(username='test_user').first()
        assert retrieved_user is not None
        assert retrieved_user.username == 'test_user'
        assert retrieved_user.check_password('password123')
        
        # Update
        retrieved_user.username = 'updated_user'
        db.session.commit()
        
        updated_user = User.query.get(user.id)
        assert updated_user.username == 'updated_user'
        
        # Delete
        db.session.delete(updated_user)
        db.session.commit()
        
        deleted_user = User.query.get(user.id)
        assert deleted_user is None
    
    def test_foreign_key_constraints(self):
        """æµ‹è¯•å¤–é”®çº¦æŸ"""
        # åˆ›å»ºè½¦è¾†
        vehicle = Vehicle(name='æµ‹è¯•è½¦è¾†', model='TEST001')
        db.session.add(vehicle)
        db.session.commit()
        
        # åˆ›å»ºæ´»åŠ¨
        activity = Activity(
            name='æµ‹è¯•æ´»åŠ¨',
            date='2025-01-15',
            vehicle_id=vehicle.id
        )
        db.session.add(activity)
        db.session.commit()
        
        # å°è¯•åˆ›å»ºå¼•ç”¨ä¸å­˜åœ¨å¤–é”®çš„è¯„ä»·
        evaluation = Evaluation(
            activity_id=999,  # ä¸å­˜åœ¨çš„æ´»åŠ¨ID
            vehicle_id=vehicle.id,
            evaluator_id=1,
            score=8,
            content='æµ‹è¯•å†…å®¹'
        )
        
        db.session.add(evaluation)
        
        # åº”è¯¥æŠ›å‡ºå®Œæ•´æ€§é”™è¯¯
        with pytest.raises(IntegrityError):
            db.session.commit()
        
        db.session.rollback()
    
    def test_cascade_delete(self):
        """æµ‹è¯•çº§è”åˆ é™¤"""
        # åˆ›å»ºå®Œæ•´çš„æ•°æ®é“¾
        vehicle = Vehicle(name='æµ‹è¯•è½¦è¾†', model='TEST001')
        db.session.add(vehicle)
        db.session.flush()  # è·å–IDä½†ä¸æäº¤
        
        activity = Activity(
            name='æµ‹è¯•æ´»åŠ¨',
            date='2025-01-15',
            vehicle_id=vehicle.id
        )
        db.session.add(activity)
        db.session.flush()
        
        evaluator = Evaluator(name='æµ‹è¯•è¯„ä»·äºº', department='æµ‹è¯•éƒ¨é—¨')
        db.session.add(evaluator)
        db.session.flush()
        
        evaluation = Evaluation(
            activity_id=activity.id,
            vehicle_id=vehicle.id,
            evaluator_id=evaluator.id,
            score=8,
            content='æµ‹è¯•å†…å®¹'
        )
        db.session.add(evaluation)
        db.session.commit()
        
        # éªŒè¯æ•°æ®åˆ›å»ºæˆåŠŸ
        assert Evaluation.query.count() == 1
        assert Activity.query.count() == 1
        
        # åˆ é™¤æ´»åŠ¨ï¼Œåº”è¯¥çº§è”åˆ é™¤è¯„ä»·
        db.session.delete(activity)
        db.session.commit()
        
        # éªŒè¯çº§è”åˆ é™¤
        assert Activity.query.count() == 0
        assert Evaluation.query.count() == 0  # åº”è¯¥è¢«çº§è”åˆ é™¤
        assert Vehicle.query.count() == 1     # è½¦è¾†ä¸åº”è¯¥è¢«åˆ é™¤
        assert Evaluator.query.count() == 1   # è¯„ä»·äººä¸åº”è¯¥è¢«åˆ é™¤
    
    def test_unique_constraints(self):
        """æµ‹è¯•å”¯ä¸€æ€§çº¦æŸ"""
        # åˆ›å»ºç”¨æˆ·
        user1 = User(username='unique_user')
        user1.set_password('password123')
        db.session.add(user1)
        db.session.commit()
        
        # å°è¯•åˆ›å»ºåŒåç”¨æˆ·
        user2 = User(username='unique_user')
        user2.set_password('password456')
        db.session.add(user2)
        
        # åº”è¯¥æŠ›å‡ºå®Œæ•´æ€§é”™è¯¯
        with pytest.raises(IntegrityError):
            db.session.commit()
        
        db.session.rollback()
    
    def test_database_transactions(self):
        """æµ‹è¯•æ•°æ®åº“äº‹åŠ¡"""
        initial_count = User.query.count()
        
        try:
            # å¼€å§‹äº‹åŠ¡
            user1 = User(username='user1')
            user1.set_password('password1')
            db.session.add(user1)
            
            user2 = User(username='user2')
            user2.set_password('password2')
            db.session.add(user2)
            
            # æ•…æ„åˆ›å»ºä¸€ä¸ªä¼šå¤±è´¥çš„æ“ä½œ
            duplicate_user = User(username='user1')  # é‡å¤ç”¨æˆ·å
            db.session.add(duplicate_user)
            
            db.session.commit()
            
        except IntegrityError:
            db.session.rollback()
        
        # éªŒè¯å›æ»šåæ•°æ®æ²¡æœ‰å˜åŒ–
        final_count = User.query.count()
        assert final_count == initial_count
    
    def test_query_performance(self):
        """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½"""
        import time
        
        # åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
        vehicles = []
        for i in range(100):
            vehicle = Vehicle(name=f'è½¦è¾†{i}', model=f'MODEL{i:03d}')
            vehicles.append(vehicle)
        
        db.session.add_all(vehicles)
        db.session.commit()
        
        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        start_time = time.time()
        results = Vehicle.query.filter(Vehicle.name.like('%è½¦è¾†%')).all()
        query_time = time.time() - start_time
        
        assert len(results) == 100
        assert query_time < 1.0  # æŸ¥è¯¢æ—¶é—´åº”è¯¥å°äº1ç§’
    
    def test_concurrent_access(self):
        """æµ‹è¯•å¹¶å‘è®¿é—®"""
        import threading
        import time
        
        results = []
        errors = []
        
        def create_user(user_id):
            try:
                user = User(username=f'concurrent_user_{user_id}')
                user.set_password('password123')
                db.session.add(user)
                db.session.commit()
                results.append(user_id)
            except Exception as e:
                errors.append(str(e))
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹åŒæ—¶æ“ä½œæ•°æ®åº“
        threads = []
        for i in range(10):
            thread = threading.Thread(target=create_user, args=(i,))
            threads.append(thread)
        
        # å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        for thread in threads:
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯ç»“æœ
        assert len(results) == 10  # æ‰€æœ‰ç”¨æˆ·éƒ½åº”è¯¥åˆ›å»ºæˆåŠŸ
        assert len(errors) == 0    # ä¸åº”è¯¥æœ‰é”™è¯¯
        
        # éªŒè¯æ•°æ®åº“ä¸­çš„ç”¨æˆ·æ•°é‡
        user_count = User.query.filter(User.username.like('concurrent_user_%')).count()
        assert user_count == 10
```

### 3.3 ç³»ç»Ÿæµ‹è¯•è§„èŒƒ

#### 3.3.1 ç«¯åˆ°ç«¯æµ‹è¯•

```python
# tests/system/test_e2e_workflow.py
import pytest
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options

@pytest.fixture(scope="session")
def driver():
    """åˆ›å»ºWebDriverå®ä¾‹"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--window-size=1920,1080')
    
    driver = webdriver.Chrome(options=chrome_options)
    driver.implicitly_wait(10)
    
    yield driver
    
    driver.quit()

@pytest.fixture
def base_url():
    """æµ‹è¯•ç¯å¢ƒåŸºç¡€URL"""
    return "http://localhost:5000"

class TestCompleteEvaluationWorkflow:
    """å®Œæ•´è¯„ä»·æµç¨‹ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def test_user_evaluation_journey(self, driver, base_url):
        """æµ‹è¯•ç”¨æˆ·å®Œæ•´è¯„ä»·æµç¨‹"""
        # 1. è®¿é—®é¦–é¡µ
        driver.get(base_url)
        assert "è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿ" in driver.title
        
        # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "main-container"))
        )
        
        # 2. éªŒè¯é¦–é¡µå…ƒç´ 
        vehicle_info = driver.find_element(By.CLASS_NAME, "vehicle-info")
        assert vehicle_info.is_displayed()
        
        start_button = driver.find_element(By.CLASS_NAME, "start-evaluation")
        assert start_button.is_displayed()
        assert start_button.is_enabled()
        
        # 3. å¼€å§‹è¯„ä»·
        start_button.click()
        
        # 4. è¯„ä»·åˆ†ç±»é¡µé¢
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "categories-grid"))
        )
        
        # éªŒè¯åˆ†ç±»å¡ç‰‡
        category_cards = driver.find_elements(By.CLASS_NAME, "category-card")
        assert len(category_cards) >= 7  # è‡³å°‘7ä¸ªåˆ†ç±»
        
        # éªŒè¯æ¯ä¸ªåˆ†ç±»å¡ç‰‡çš„ç»“æ„
        first_card = category_cards[0]
        assert first_card.find_element(By.CLASS_NAME, "category-icon")
        assert first_card.find_element(By.CLASS_NAME, "category-name")
        
        # 5. é€‰æ‹©ç¬¬ä¸€ä¸ªåˆ†ç±»
        first_card.click()
        
        # 6. è¯„ä»·å½•å…¥é¡µé¢
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "evaluation-form"))
        )
        
        # éªŒè¯è¯„ä»·è¡¨å•å…ƒç´ 
        assert driver.find_element(By.ID, "score-buttons")
        assert driver.find_element(By.ID, "evaluator-select")
        assert driver.find_element(By.ID, "evaluationContent")
        
        # 7. å¡«å†™è¯„ä»·ä¿¡æ¯
        # é€‰æ‹©è¯„åˆ†
        score_button = driver.find_element(By.CSS_SELECTOR, "[data-score='8']")
        score_button.click()
        
        # é€‰æ‹©è¯„ä»·äºº
        evaluator_select = Select(driver.find_element(By.ID, "evaluator-select"))
        evaluator_select.select_by_index(1)  # é€‰æ‹©ç¬¬ä¸€ä¸ªè¯„ä»·äºº
        
        # å¡«å†™è¯„ä»·å†…å®¹
        content_editor = driver.find_element(By.ID, "evaluationContent")
        test_content = "è¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯æµ‹è¯•çš„è¯„ä»·å†…å®¹ï¼ŒåŒ…å«è¯¦ç»†çš„æµ‹è¯•ä¿¡æ¯å’Œåé¦ˆã€‚"
        content_editor.clear()
        content_editor.send_keys(test_content)
        
        # 8. æäº¤è¯„ä»·
        submit_button = driver.find_element(By.ID, "submit-evaluation")
        submit_button.click()
        
        # 9. éªŒè¯æäº¤æˆåŠŸ
        success_alert = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "alert-success"))
        )
        assert "è¯„ä»·æäº¤æˆåŠŸ" in success_alert.text
        
        # 10. è¿”å›åˆ†ç±»é¡µé¢
        WebDriverWait(driver, 5).until(
            EC.url_contains("/categories")
        )
        
        # 11. éªŒè¯è¯„ä»·è®¡æ•°æ›´æ–°
        updated_card = driver.find_element(By.CLASS_NAME, "category-card")
        badge = updated_card.find_element(By.CLASS_NAME, "category-badge")
        assert int(badge.text) > 0
        
        # 12. æŸ¥çœ‹è¯„ä»·è¯¦æƒ…
        badge.click()
        
        # éªŒè¯è¯„ä»·è¯¦æƒ…æ¨¡æ€æ¡†
        modal = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "evaluationModal"))
        )
        assert modal.is_displayed()
        
        # éªŒè¯è¯„ä»·å†…å®¹æ˜¾ç¤º
        evaluation_items = modal.find_elements(By.CLASS_NAME, "evaluation-item")
        assert len(evaluation_items) > 0
        
        # éªŒè¯åˆšæäº¤çš„è¯„ä»·æ˜¯å¦æ˜¾ç¤º
        latest_evaluation = evaluation_items[0]
        assert test_content in latest_evaluation.text
    
    def test_language_switching(self, driver, base_url):
        """æµ‹è¯•è¯­è¨€åˆ‡æ¢åŠŸèƒ½"""
        driver.get(base_url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "lang-switch"))
        )
        
        # è·å–åˆå§‹è¯­è¨€ä¸‹çš„æ–‡æœ¬
        title_element = driver.find_element(By.CLASS_NAME, "page-title")
        initial_title = title_element.text
        
        # åˆ‡æ¢åˆ°è‹±æ–‡
        en_button = driver.find_element(By.CLASS_NAME, "lang-en")
        en_button.click()
        
        # ç­‰å¾…è¯­è¨€åˆ‡æ¢å®Œæˆ
        time.sleep(1)
        
        # éªŒè¯æ–‡æœ¬å·²æ›´æ”¹
        updated_title = title_element.text
        assert updated_title != initial_title
        
        # åˆ‡å›ä¸­æ–‡
        zh_button = driver.find_element(By.CLASS_NAME, "lang-zh")
        zh_button.click()
        
        time.sleep(1)
        
        # éªŒè¯åˆ‡å›ä¸­æ–‡
        final_title = title_element.text
        assert final_title == initial_title
    
    def test_responsive_design(self, driver, base_url):
        """æµ‹è¯•å“åº”å¼è®¾è®¡"""
        driver.get(base_url)
        
        # æµ‹è¯•ä¸åŒå±å¹•å°ºå¯¸
        screen_sizes = [
            (1920, 1080),  # æ¡Œé¢
            (1024, 768),   # å¹³æ¿æ¨ªå±
            (768, 1024),   # å¹³æ¿ç«–å±
            (375, 667),    # æ‰‹æœº
        ]
        
        for width, height in screen_sizes:
            driver.set_window_size(width, height)
            time.sleep(1)  # ç­‰å¾…å¸ƒå±€è°ƒæ•´
            
            # éªŒè¯å…³é”®å…ƒç´ åœ¨ä¸åŒå°ºå¯¸ä¸‹éƒ½å¯è§
            main_container = driver.find_element(By.CLASS_NAME, "main-container")
            assert main_container.is_displayed()
            
            # éªŒè¯å¯¼èˆªå…ƒç´ 
            if width >= 768:  # å¤§å±å¹•æ˜¾ç¤ºå®Œæ•´å¯¼èˆª
                nav_elements = driver.find_elements(By.CLASS_NAME, "nav-item")
                assert len(nav_elements) > 0
            
            # éªŒè¯å†…å®¹åŒºåŸŸä¸ä¼šæº¢å‡º
            body_width = driver.execute_script("return document.body.scrollWidth")
            assert body_width <= width + 20  # å…è®¸å°è¯¯å·®

class TestAdminWorkflow:
    """ç®¡ç†å‘˜å·¥ä½œæµç¨‹æµ‹è¯•"""
    
    def test_admin_login_and_management(self, driver, base_url):
        """æµ‹è¯•ç®¡ç†å‘˜ç™»å½•å’Œç®¡ç†åŠŸèƒ½"""
        # 1. è®¿é—®ç®¡ç†åå°ç™»å½•é¡µ
        driver.get(f"{base_url}/admin/login")
        
        # 2. å¡«å†™ç™»å½•ä¿¡æ¯
        username_input = driver.find_element(By.ID, "username")
        password_input = driver.find_element(By.ID, "password")
        
        username_input.send_keys("admin")
        password_input.send_keys("password")
        
        # 3. æäº¤ç™»å½•
        login_button = driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
        login_button.click()
        
        # 4. éªŒè¯ç™»å½•æˆåŠŸï¼Œè·³è½¬åˆ°ç®¡ç†é¢æ¿
        WebDriverWait(driver, 10).until(
            EC.url_contains("/admin/dashboard")
        )
        
        # 5. éªŒè¯ç®¡ç†é¢æ¿å…ƒç´ 
        dashboard = driver.find_element(By.CLASS_NAME, "dashboard")
        assert dashboard.is_displayed()
        
        # éªŒè¯ç®¡ç†æ¨¡å—
        management_sections = [
            "vehicle-management",
            "evaluator-management", 
            "activity-management",
            "category-management"
        ]
        
        for section_id in management_sections:
            section = driver.find_element(By.ID, section_id)
            assert section.is_displayed()
        
        # 6. æµ‹è¯•æ·»åŠ è½¦è¾†åŠŸèƒ½
        add_vehicle_btn = driver.find_element(By.ID, "add-vehicle-btn")
        add_vehicle_btn.click()
        
        # å¡«å†™è½¦è¾†ä¿¡æ¯
        WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.ID, "addVehicleModal"))
        )
        
        vehicle_name = driver.find_element(By.ID, "vehicleName")
        vehicle_model = driver.find_element(By.ID, "vehicleModel")
        
        vehicle_name.send_keys("æµ‹è¯•è½¦è¾†E2E")
        vehicle_model.send_keys("E2E001")
        
        # æäº¤è½¦è¾†ä¿¡æ¯
        submit_vehicle = driver.find_element(By.CSS_SELECTOR, "#addVehicleModal button[type='submit']")
        submit_vehicle.click()
        
        # 7. éªŒè¯è½¦è¾†æ·»åŠ æˆåŠŸ
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "alert-success"))
        )
        
        # éªŒè¯è½¦è¾†å‡ºç°åœ¨åˆ—è¡¨ä¸­
        vehicle_rows = driver.find_elements(By.CSS_SELECTOR, "#vehicles-tbody tr")
        vehicle_names = [row.find_elements(By.TAG_NAME, "td")[1].text for row in vehicle_rows]
        assert "æµ‹è¯•è½¦è¾†E2E" in vehicle_names
    
    def test_evaluation_data_export(self, driver, base_url):
        """æµ‹è¯•è¯„ä»·æ•°æ®å¯¼å‡ºåŠŸèƒ½"""
        # ç™»å½•ç®¡ç†åå°
        driver.get(f"{base_url}/admin/login")
        
        username_input = driver.find_element(By.ID, "username")
        password_input = driver.find_element(By.ID, "password")
        
        username_input.send_keys("admin")
        password_input.send_keys("password")
        
        login_button = driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
        login_button.click()
        
        WebDriverWait(driver, 10).until(
            EC.url_contains("/admin/dashboard")
        )
        
        # æŸ¥çœ‹è¯„ä»·æ•°æ®
        view_evaluations_btn = driver.find_element(By.CSS_SELECTOR, "[onclick*='viewEvaluations']")
        view_evaluations_btn.click()
        
        # ç­‰å¾…è¯„ä»·é¡µé¢åŠ è½½
        WebDriverWait(driver, 10).until(
            EC.url_contains("/admin/evaluations")
        )
        
        # éªŒè¯å¯¼å‡ºæŒ‰é’®å­˜åœ¨
        export_buttons = driver.find_elements(By.CSS_SELECTOR, "[onclick*='exportReport']")
        assert len(export_buttons) > 0
        
        # ç‚¹å‡»å¯¼å‡ºï¼ˆè¿™é‡ŒåªéªŒè¯æŒ‰é’®å¯ç‚¹å‡»ï¼Œå®é™…æ–‡ä»¶ä¸‹è½½éœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        export_buttons[0].click()
        
        # éªŒè¯æ²¡æœ‰JavaScripté”™è¯¯ï¼ˆé€šè¿‡æ£€æŸ¥alertæˆ–é”™è¯¯ä¿¡æ¯ï¼‰
        time.sleep(2)  # ç­‰å¾…å¯èƒ½çš„é”™è¯¯æç¤º
        
        # å¦‚æœæœ‰é”™è¯¯æç¤ºï¼Œè¿™é‡Œä¼šæ•è·åˆ°
        try:
            error_alert = driver.find_element(By.CLASS_NAME, "alert-danger")
            pytest.fail(f"å¯¼å‡ºåŠŸèƒ½å‡ºç°é”™è¯¯: {error_alert.text}")
        except:
            pass  # æ²¡æœ‰é”™è¯¯ï¼Œæµ‹è¯•é€šè¿‡
```

### 3.4 æ€§èƒ½æµ‹è¯•è§„èŒƒ

#### 3.4.1 è´Ÿè½½æµ‹è¯•

```python
# tests/performance/test_load.py
import pytest
import requests
import time
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def base_url(self):
        return "http://localhost:5000"
    
    @pytest.fixture
    def auth_session(self, base_url):
        """åˆ›å»ºå·²è®¤è¯çš„ä¼šè¯"""
        session = requests.Session()
        
        # æ‰§è¡Œç™»å½•
        login_data = {
            'username': 'admin',
            'password': 'password'
        }
        response = session.post(f"{base_url}/admin/login", data=login_data)
        assert response.status_code == 200
        
        return session
    
    def test_homepage_load_time(self, base_url):
        """æµ‹è¯•é¦–é¡µåŠ è½½æ—¶é—´"""
        response_times = []
        
        for _ in range(10):
            start_time = time.time()
            response = requests.get(base_url)
            end_time = time.time()
            
            assert response.status_code == 200
            response_times.append(end_time - start_time)
        
        avg_time = statistics.mean(response_times)
        p95_time = statistics.quantiles(response_times, n=20)[18]  # 95th percentile
        
        print(f"\né¦–é¡µåŠ è½½æ€§èƒ½:")
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
        print(f"95%å“åº”æ—¶é—´: {p95_time:.3f}s")
        
        # æ€§èƒ½è¦æ±‚ï¼šå¹³å‡å“åº”æ—¶é—´å°äº2ç§’
        assert avg_time < 2.0, f"é¦–é¡µå¹³å‡åŠ è½½æ—¶é—´è¿‡é•¿: {avg_time:.3f}s"
        assert p95_time < 3.0, f"é¦–é¡µ95%åŠ è½½æ—¶é—´è¿‡é•¿: {p95_time:.3f}s"
    
    def test_api_response_time(self, base_url, auth_session):
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        api_endpoints = [
            '/api/activities',
            '/api/evaluations/1/1',
            '/api/evaluation_counts/1/1'
        ]
        
        results = {}
        
        for endpoint in api_endpoints:
            response_times = []
            
            for _ in range(20):
                start_time = time.time()
                response = auth_session.get(f"{base_url}{endpoint}")
                end_time = time.time()
                
                if response.status_code == 200:
                    response_times.append(end_time - start_time)
            
            if response_times:
                avg_time = statistics.mean(response_times)
                results[endpoint] = avg_time
                
                print(f"\n{endpoint} å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
                
                # APIå“åº”æ—¶é—´è¦æ±‚ï¼šå°äº1ç§’
                assert avg_time < 1.0, f"API {endpoint} å“åº”æ—¶é—´è¿‡é•¿: {avg_time:.3f}s"
        
        return results
    
    def test_concurrent_users(self, base_url):
        """æµ‹è¯•å¹¶å‘ç”¨æˆ·è®¿é—®"""
        def make_request():
            try:
                start_time = time.time()
                response = requests.get(base_url, timeout=10)
                end_time = time.time()
                
                return {
                    'status_code': response.status_code,
                    'response_time': end_time - start_time,
                    'success': response.status_code == 200
                }
            except Exception as e:
                return {
                    'status_code': None,
                    'response_time': None,
                    'success': False,
                    'error': str(e)
                }
        
        # æ¨¡æ‹Ÿ50ä¸ªå¹¶å‘ç”¨æˆ·
        concurrent_users = 50
        results = []
        
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(make_request) for _ in range(concurrent_users)]
            
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
        
        # åˆ†æç»“æœ
        successful_requests = [r for r in results if r['success']]
        failed_requests = [r for r in results if not r['success']]
        
        success_rate = len(successful_requests) / len(results)
        avg_response_time = statistics.mean([r['response_time'] for r in successful_requests])
        
        print(f"\nå¹¶å‘æµ‹è¯•ç»“æœ:")
        print(f"æ€»è¯·æ±‚æ•°: {len(results)}")
        print(f"æˆåŠŸè¯·æ±‚æ•°: {len(successful_requests)}")
        print(f"å¤±è´¥è¯·æ±‚æ•°: {len(failed_requests)}")
        print(f"æˆåŠŸç‡: {success_rate:.2%}")
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        
        # æ€§èƒ½è¦æ±‚
        assert success_rate >= 0.95, f"æˆåŠŸç‡è¿‡ä½: {success_rate:.2%}"
        assert avg_response_time < 5.0, f"å¹¶å‘æƒ…å†µä¸‹å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.3f}s"
        
        # æ‰“å°å¤±è´¥è¯·æ±‚çš„é”™è¯¯ä¿¡æ¯
        if failed_requests:
            print("\nå¤±è´¥è¯·æ±‚é”™è¯¯ä¿¡æ¯:")
            for i, req in enumerate(failed_requests[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                if 'error' in req:
                    print(f"  {i+1}. {req['error']}")
    
    def test_evaluation_creation_performance(self, base_url, auth_session):
        """æµ‹è¯•è¯„ä»·åˆ›å»ºæ€§èƒ½"""
        evaluation_data = {
            'activity_id': 1,
            'vehicle_id': 1,
            'evaluator_id': 1,
            'category_id': 1,
            'score': 8,
            'content': 'æ€§èƒ½æµ‹è¯•è¯„ä»·å†…å®¹'
        }
        
        response_times = []
        
        for i in range(50):
            # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºå”¯ä¸€å†…å®¹
            data = evaluation_data.copy()
            data['content'] = f'æ€§èƒ½æµ‹è¯•è¯„ä»·å†…å®¹ {i}'
            
            start_time = time.time()
            response = auth_session.post(
                f"{base_url}/api/save_evaluation",
                json=data,
                headers={'Content-Type': 'application/json'}
            )
            end_time = time.time()
            
            if response.status_code == 200:
                response_times.append(end_time - start_time)
            else:
                print(f"è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
        
        if response_times:
            avg_time = statistics.mean(response_times)
            p95_time = statistics.quantiles(response_times, n=20)[18]
            
            print(f"\nè¯„ä»·åˆ›å»ºæ€§èƒ½:")
            print(f"æˆåŠŸåˆ›å»º: {len(response_times)}/50")
            print(f"å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
            print(f"95%å“åº”æ—¶é—´: {p95_time:.3f}s")
            
            # æ€§èƒ½è¦æ±‚
            assert avg_time < 2.0, f"è¯„ä»·åˆ›å»ºå¹³å‡æ—¶é—´è¿‡é•¿: {avg_time:.3f}s"
            assert p95_time < 3.0, f"è¯„ä»·åˆ›å»º95%æ—¶é—´è¿‡é•¿: {p95_time:.3f}s"
    
    def test_memory_usage(self, base_url):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        import psutil
        import os
        
        # è·å–å½“å‰è¿›ç¨‹IDï¼ˆå‡è®¾æµ‹è¯•æ—¶ç³»ç»Ÿæ­£åœ¨è¿è¡Œï¼‰
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…éƒ¨ç½²æƒ…å†µè°ƒæ•´
        
        print(f"\nç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ:")
        
        # ç³»ç»Ÿå†…å­˜ä½¿ç”¨
        memory = psutil.virtual_memory()
        print(f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡: {memory.percent}%")
        print(f"å¯ç”¨å†…å­˜: {memory.available / 1024 / 1024:.0f}MB")
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        print(f"ç³»ç»ŸCPUä½¿ç”¨ç‡: {cpu_percent}%")
        
        # ç£ç›˜ä½¿ç”¨ç‡
        disk = psutil.disk_usage('/')
        print(f"ç£ç›˜ä½¿ç”¨ç‡: {disk.percent}%")
        
        # åŸºæœ¬çš„èµ„æºä½¿ç”¨æ£€æŸ¥
        assert memory.percent < 85, f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent}%"
        assert cpu_percent < 80, f"ç³»ç»ŸCPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent}%"
        assert disk.percent < 90, f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk.percent}%"
```

#### 3.4.2 å‹åŠ›æµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# stress_test.sh - å‹åŠ›æµ‹è¯•è„šæœ¬

BASE_URL="http://localhost:5000"
CONCURRENT_USERS=100
TEST_DURATION=300  # 5åˆ†é’Ÿ
RAMP_UP_TIME=60    # 1åˆ†é’Ÿçˆ¬å¡æ—¶é—´

echo "ğŸš€ å¼€å§‹å‹åŠ›æµ‹è¯•..."
echo "ç›®æ ‡URL: $BASE_URL"
echo "å¹¶å‘ç”¨æˆ·æ•°: $CONCURRENT_USERS"
echo "æµ‹è¯•æŒç»­æ—¶é—´: ${TEST_DURATION}ç§’"

# ä½¿ç”¨Apache Benchè¿›è¡Œå‹åŠ›æµ‹è¯•
echo "ğŸ“Š æ‰§è¡Œå¹¶å‘æµ‹è¯•..."

# é¦–é¡µå‹åŠ›æµ‹è¯•
ab -n 1000 -c 50 -g homepage.data "$BASE_URL/" > homepage_results.txt

# APIå‹åŠ›æµ‹è¯•
ab -n 500 -c 25 -H "Content-Type: application/json" \
   -p evaluation_data.json "$BASE_URL/api/save_evaluation" > api_results.txt

# åˆ†æç»“æœ
echo "ğŸ“ˆ åˆ†ææµ‹è¯•ç»“æœ..."

# æå–å…³é”®æŒ‡æ ‡
homepage_rps=$(grep "Requests per second" homepage_results.txt | awk '{print $4}')
homepage_mean_time=$(grep "Time per request.*mean" homepage_results.txt | head -1 | awk '{print $4}')
homepage_95_percentile=$(grep "95%" homepage_results.txt | awk '{print $2}')

api_rps=$(grep "Requests per second" api_results.txt | awk '{print $4}')
api_mean_time=$(grep "Time per request.*mean" api_results.txt | head -1 | awk '{print $4}')
api_95_percentile=$(grep "95%" api_results.txt | awk '{print $2}')

echo "âœ… é¦–é¡µæ€§èƒ½ç»“æœ:"
echo "  - æ¯ç§’è¯·æ±‚æ•°: $homepage_rps"
echo "  - å¹³å‡å“åº”æ—¶é—´: ${homepage_mean_time}ms"
echo "  - 95%å“åº”æ—¶é—´: ${homepage_95_percentile}ms"

echo "âœ… APIæ€§èƒ½ç»“æœ:"
echo "  - æ¯ç§’è¯·æ±‚æ•°: $api_rps"
echo "  - å¹³å‡å“åº”æ—¶é—´: ${api_mean_time}ms"
echo "  - 95%å“åº”æ—¶é—´: ${api_95_percentile}ms"

# æ€§èƒ½åŸºå‡†æ£€æŸ¥
homepage_rps_num=$(echo $homepage_rps | cut -d'[' -f1)
api_rps_num=$(echo $api_rps | cut -d'[' -f1)

if (( $(echo "$homepage_rps_num >= 100" | bc -l) )); then
    echo "âœ… é¦–é¡µRPSæ»¡è¶³è¦æ±‚ (>= 100)"
else
    echo "âŒ é¦–é¡µRPSä¸æ»¡è¶³è¦æ±‚: $homepage_rps_num"
fi

if (( $(echo "$api_rps_num >= 50" | bc -l) )); then
    echo "âœ… API RPSæ»¡è¶³è¦æ±‚ (>= 50)"
else
    echo "âŒ API RPSä¸æ»¡è¶³è¦æ±‚: $api_rps_num"
fi

echo "ğŸ‰ å‹åŠ›æµ‹è¯•å®Œæˆï¼"
```

## 4. æµ‹è¯•è®¡åˆ’

### 4.1 æµ‹è¯•é˜¶æ®µè§„åˆ’

```mermaid
gantt
    title æµ‹è¯•é˜¶æ®µè§„åˆ’
    dateFormat  YYYY-MM-DD
    section å•å…ƒæµ‹è¯•
    æ¨¡å‹å±‚æµ‹è¯•           :done,    ut1, 2025-01-01, 2025-01-03
    æœåŠ¡å±‚æµ‹è¯•           :done,    ut2, 2025-01-02, 2025-01-05
    å·¥å…·å‡½æ•°æµ‹è¯•         :done,    ut3, 2025-01-03, 2025-01-06
    å‰ç«¯ç»„ä»¶æµ‹è¯•         :active,  ut4, 2025-01-04, 2025-01-08
    
    section é›†æˆæµ‹è¯•
    APIæ¥å£æµ‹è¯•          :         it1, 2025-01-06, 2025-01-10
    æ•°æ®åº“é›†æˆæµ‹è¯•       :         it2, 2025-01-07, 2025-01-11
    ç¬¬ä¸‰æ–¹é›†æˆæµ‹è¯•       :         it3, 2025-01-09, 2025-01-12
    
    section ç³»ç»Ÿæµ‹è¯•
    åŠŸèƒ½æµ‹è¯•             :         st1, 2025-01-11, 2025-01-16
    UIæµ‹è¯•               :         st2, 2025-01-13, 2025-01-18
    å…¼å®¹æ€§æµ‹è¯•           :         st3, 2025-01-15, 2025-01-19
    
    section æ€§èƒ½æµ‹è¯•
    è´Ÿè½½æµ‹è¯•             :         pt1, 2025-01-17, 2025-01-20
    å‹åŠ›æµ‹è¯•             :         pt2, 2025-01-18, 2025-01-21
    
    section å®‰å…¨æµ‹è¯•
    å®‰å…¨æ‰«æ             :         se1, 2025-01-19, 2025-01-22
    æ¸—é€æµ‹è¯•             :         se2, 2025-01-20, 2025-01-23
    
    section éªŒæ”¶æµ‹è¯•
    ç”¨æˆ·éªŒæ”¶æµ‹è¯•         :         at1, 2025-01-22, 2025-01-25
    ç”Ÿäº§ç¯å¢ƒéªŒè¯         :         at2, 2025-01-24, 2025-01-26
```

### 4.2 æµ‹è¯•ç”¨ä¾‹ç®¡ç†

#### 4.2.1 æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿

```markdown
# æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿

## ç”¨ä¾‹åŸºç¡€ä¿¡æ¯
- **ç”¨ä¾‹ID**: TC_001
- **ç”¨ä¾‹æ ‡é¢˜**: ç”¨æˆ·ç™»å½•åŠŸèƒ½æµ‹è¯•
- **æµ‹è¯•çº§åˆ«**: ç³»ç»Ÿæµ‹è¯•
- **ä¼˜å…ˆçº§**: é«˜
- **åˆ›å»ºäºº**: æµ‹è¯•å·¥ç¨‹å¸ˆ
- **åˆ›å»ºæ—¥æœŸ**: 2025-01-01
- **ä¿®æ”¹æ—¥æœŸ**: 2025-01-15

## æµ‹è¯•ç›®æ ‡
éªŒè¯ç”¨æˆ·èƒ½å¤Ÿä½¿ç”¨æ­£ç¡®çš„ç”¨æˆ·åå’Œå¯†ç æˆåŠŸç™»å½•ç³»ç»Ÿ

## å‰ç½®æ¡ä»¶
1. ç³»ç»Ÿå·²éƒ¨ç½²å¹¶æ­£å¸¸è¿è¡Œ
2. æµ‹è¯•æ•°æ®åº“å·²å‡†å¤‡ï¼ŒåŒ…å«æœ‰æ•ˆç”¨æˆ·è´¦æˆ·
3. æµè§ˆå™¨ç¯å¢ƒå·²å‡†å¤‡

## æµ‹è¯•æ­¥éª¤
1. æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—®ç™»å½•é¡µé¢
2. è¾“å…¥æœ‰æ•ˆç”¨æˆ·å
3. è¾“å…¥å¯¹åº”å¯†ç 
4. ç‚¹å‡»ç™»å½•æŒ‰é’®

## é¢„æœŸç»“æœ
1. é¡µé¢è·³è½¬åˆ°ç®¡ç†é¢æ¿
2. æ˜¾ç¤ºç”¨æˆ·æ¬¢è¿ä¿¡æ¯
3. æ˜¾ç¤ºæ­£ç¡®çš„èœå•é€‰é¡¹

## æµ‹è¯•æ•°æ®
- ç”¨æˆ·å: admin
- å¯†ç : password123

## å®é™…ç»“æœ
[æµ‹è¯•æ‰§è¡Œæ—¶å¡«å†™]

## æµ‹è¯•çŠ¶æ€
- [ ] é€šè¿‡
- [ ] å¤±è´¥
- [ ] é˜»å¡
- [ ] è·³è¿‡

## ç¼ºé™·ä¿¡æ¯
[å¦‚æœ‰ç¼ºé™·ï¼Œè®°å½•ç¼ºé™·IDå’Œæè¿°]

## å¤‡æ³¨
[å…¶ä»–éœ€è¦è¯´æ˜çš„ä¿¡æ¯]
```

#### 4.2.2 æµ‹è¯•ç”¨ä¾‹åˆ†ç±»

**åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹**:
```yaml
functional_test_cases:
  user_management:
    - TC_001: ç”¨æˆ·ç™»å½•åŠŸèƒ½
    - TC_002: ç”¨æˆ·ç™»å‡ºåŠŸèƒ½
    - TC_003: å¯†ç ä¿®æ”¹åŠŸèƒ½
    - TC_004: ç”¨æˆ·æƒé™éªŒè¯
  
  evaluation_management:
    - TC_011: åˆ›å»ºè¯„ä»·åŠŸèƒ½
    - TC_012: æŸ¥çœ‹è¯„ä»·åˆ—è¡¨
    - TC_013: ä¿®æ”¹è¯„ä»·å†…å®¹
    - TC_014: åˆ é™¤è¯„ä»·è®°å½•
    - TC_015: è¯„ä»·ç»Ÿè®¡æ˜¾ç¤º
  
  vehicle_management:
    - TC_021: æ·»åŠ è½¦è¾†ä¿¡æ¯
    - TC_022: ä¿®æ”¹è½¦è¾†ä¿¡æ¯
    - TC_023: åˆ é™¤è½¦è¾†è®°å½•
    - TC_024: è½¦è¾†ä¿¡æ¯æŸ¥è¯¢
    - TC_025: PDFæ–‡æ¡£ä¸Šä¼ 
  
  report_generation:
    - TC_031: WordæŠ¥å‘Šç”Ÿæˆ
    - TC_032: æŠ¥å‘Šæ•°æ®å‡†ç¡®æ€§
    - TC_033: æŠ¥å‘Šæ ¼å¼éªŒè¯
    - TC_034: æŠ¥å‘Šä¸‹è½½åŠŸèƒ½
```

**éåŠŸèƒ½æµ‹è¯•ç”¨ä¾‹**:
```yaml
non_functional_test_cases:
  performance:
    - TC_101: é¦–é¡µåŠ è½½æ€§èƒ½
    - TC_102: APIå“åº”æ—¶é—´
    - TC_103: å¹¶å‘ç”¨æˆ·æµ‹è¯•
    - TC_104: å¤§æ•°æ®é‡å¤„ç†
  
  security:
    - TC_201: SQLæ³¨å…¥æµ‹è¯•
    - TC_202: XSSæ”»å‡»é˜²æŠ¤
    - TC_203: CSRFæ”»å‡»é˜²æŠ¤
    - TC_204: æ–‡ä»¶ä¸Šä¼ å®‰å…¨
    - TC_205: æƒé™ç»•è¿‡æµ‹è¯•
  
  compatibility:
    - TC_301: Chromeæµè§ˆå™¨å…¼å®¹
    - TC_302: Firefoxæµè§ˆå™¨å…¼å®¹
    - TC_303: Safariæµè§ˆå™¨å…¼å®¹
    - TC_304: iPadè®¾å¤‡å…¼å®¹
    - TC_305: ä¸åŒåˆ†è¾¨ç‡é€‚é…
  
  usability:
    - TC_401: ç•Œé¢å‹å¥½æ€§
    - TC_402: æ“ä½œä¾¿æ·æ€§
    - TC_403: é”™è¯¯æç¤ºæ¸…æ™°æ€§
    - TC_404: å¸®åŠ©æ–‡æ¡£å¯ç”¨æ€§
```

### 4.3 ç¼ºé™·ç®¡ç†

#### 4.3.1 ç¼ºé™·åˆ†ç±»æ ‡å‡†

**ä¸¥é‡ç¨‹åº¦åˆ†çº§**:
- **è‡´å‘½ (Critical)**: ç³»ç»Ÿå´©æºƒã€æ•°æ®ä¸¢å¤±ã€å®‰å…¨æ¼æ´
- **ä¸¥é‡ (Major)**: æ ¸å¿ƒåŠŸèƒ½æ— æ³•ä½¿ç”¨ã€æ€§èƒ½ä¸¥é‡ä¸‹é™
- **ä¸€èˆ¬ (Minor)**: åŠŸèƒ½éƒ¨åˆ†å¼‚å¸¸ã€ç•Œé¢æ˜¾ç¤ºé—®é¢˜
- **è½»å¾® (Trivial)**: æ–‡æœ¬é”™è¯¯ã€ç•Œé¢ä¼˜åŒ–å»ºè®®

**ä¼˜å…ˆçº§åˆ†çº§**:
- **P0 - ç´§æ€¥**: ç«‹å³ä¿®å¤ï¼Œé˜»å¡å‘å¸ƒ
- **P1 - é«˜**: æœ¬ç‰ˆæœ¬å¿…é¡»ä¿®å¤
- **P2 - ä¸­**: ä¸‹ç‰ˆæœ¬ä¿®å¤
- **P3 - ä½**: åç»­ç‰ˆæœ¬è€ƒè™‘ä¿®å¤

#### 4.3.2 ç¼ºé™·æŠ¥å‘Šæ¨¡æ¿

```markdown
# ç¼ºé™·æŠ¥å‘Š

## åŸºç¡€ä¿¡æ¯
- **ç¼ºé™·ID**: BUG_001
- **ç¼ºé™·æ ‡é¢˜**: è¯„ä»·æäº¤åé¡µé¢ç©ºç™½
- **å‘ç°äºº**: æµ‹è¯•å·¥ç¨‹å¸ˆ
- **å‘ç°æ—¶é—´**: 2025-01-15 14:30
- **ä¸¥é‡ç¨‹åº¦**: ä¸¥é‡
- **ä¼˜å…ˆçº§**: P1
- **çŠ¶æ€**: æ–°å»º

## æµ‹è¯•ç¯å¢ƒ
- **æ“ä½œç³»ç»Ÿ**: macOS 14.1
- **æµè§ˆå™¨**: Chrome 120.0.6099.129
- **æµ‹è¯•ç¯å¢ƒ**: http://test.evaluation-system.com
- **æ•°æ®åº“**: SQLite 3.40.0

## ç¼ºé™·æè¿°
ç”¨æˆ·åœ¨è¯„ä»·é¡µé¢å¡«å†™å®Œæ•´ä¿¡æ¯å¹¶ç‚¹å‡»æäº¤åï¼Œé¡µé¢å˜ä¸ºç©ºç™½ï¼Œæ— ä»»ä½•å†…å®¹æ˜¾ç¤ºã€‚

## å¤ç°æ­¥éª¤
1. ç™»å½•ç³»ç»Ÿï¼Œè¿›å…¥è¯„ä»·é¡µé¢
2. é€‰æ‹©è¯„åˆ†ä¸º8åˆ†
3. é€‰æ‹©è¯„ä»·äºº"å¼ å·¥ç¨‹å¸ˆ"
4. åœ¨å†…å®¹æ¡†è¾“å…¥"æµ‹è¯•è¯„ä»·å†…å®¹"
5. ç‚¹å‡»"æäº¤è¯„ä»·"æŒ‰é’®

## é¢„æœŸç»“æœ
- æ˜¾ç¤ºæäº¤æˆåŠŸçš„æç¤ºä¿¡æ¯
- é¡µé¢è·³è½¬å›åˆ†ç±»é€‰æ‹©é¡µé¢
- åˆ†ç±»å¡ç‰‡ä¸Šçš„æ•°å­—å¢åŠ 1

## å®é™…ç»“æœ
- é¡µé¢å˜ä¸ºå®Œå…¨ç©ºç™½
- æµè§ˆå™¨æ§åˆ¶å°æ˜¾ç¤ºJavaScripté”™è¯¯
- æ•°æ®åº“ä¸­æ²¡æœ‰æ–°å¢è¯„ä»·è®°å½•

## é”™è¯¯ä¿¡æ¯
```
Console Error:
TypeError: Cannot read property 'success' of undefined
    at handleSubmitResponse (evaluation.js:156)
    at XMLHttpRequest.xhr.onload (evaluation.js:142)
```

## é™„ä»¶
- é”™è¯¯æˆªå›¾: bug_001_screenshot.png
- æµè§ˆå™¨æ§åˆ¶å°æ—¥å¿—: bug_001_console.log
- ç½‘ç»œè¯·æ±‚è®°å½•: bug_001_network.har

## å½±å“èŒƒå›´
- æ‰€æœ‰ç”¨æˆ·æ— æ³•æäº¤è¯„ä»·
- æ ¸å¿ƒä¸šåŠ¡åŠŸèƒ½å®Œå…¨ä¸å¯ç”¨

## å»ºè®®è§£å†³æ–¹æ¡ˆ
æ£€æŸ¥evaluation.jsæ–‡ä»¶ç¬¬156è¡Œçš„å“åº”å¤„ç†é€»è¾‘

## ç›¸å…³ä¿¡æ¯
- å…³è”ç”¨ä¾‹: TC_011
- ç›¸ä¼¼ç¼ºé™·: æ— 
- å›å½’æµ‹è¯•: éœ€è¦
```

### 4.4 æµ‹è¯•è‡ªåŠ¨åŒ–

#### 4.4.1 è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶

```python
# tests/automation/framework/base_test.py
import pytest
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
import json
import os

class BaseTest:
    """è‡ªåŠ¨åŒ–æµ‹è¯•åŸºç±»"""
    
    @pytest.fixture(autouse=True)
    def setup(self, request):
        """æµ‹è¯•å‰ç½®è®¾ç½®"""
        self.config = self.load_config()
        self.driver = self.create_driver()
        self.wait = WebDriverWait(self.driver, 10)
        
        # è®¾ç½®æµ‹è¯•æ•°æ®
        self.test_data = self.load_test_data()
        
        yield
        
        # æµ‹è¯•åæ¸…ç†
        self.cleanup()
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = os.path.join(os.path.dirname(__file__), '../config/test_config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def create_driver(self):
        """åˆ›å»ºWebDriverå®ä¾‹"""
        options = webdriver.ChromeOptions()
        
        if self.config.get('headless', True):
            options.add_argument('--headless')
        
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument(f'--window-size={self.config.get("window_width", 1920)},{self.config.get("window_height", 1080)}')
        
        driver = webdriver.Chrome(options=options)
        driver.implicitly_wait(self.config.get('implicit_wait', 10))
        
        return driver
    
    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        data_path = os.path.join(os.path.dirname(__file__), '../data/test_data.json')
        with open(data_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def login_as_admin(self):
        """ç®¡ç†å‘˜ç™»å½•"""
        self.driver.get(f"{self.config['base_url']}/admin/login")
        
        username_input = self.wait.until(
            EC.presence_of_element_located((By.ID, "username"))
        )
        password_input = self.driver.find_element(By.ID, "password")
        
        username_input.send_keys(self.test_data['admin']['username'])
        password_input.send_keys(self.test_data['admin']['password'])
        
        login_button = self.driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
        login_button.click()
        
        # ç­‰å¾…ç™»å½•æˆåŠŸ
        self.wait.until(EC.url_contains("/admin/dashboard"))
    
    def navigate_to_evaluation_page(self):
        """å¯¼èˆªåˆ°è¯„ä»·é¡µé¢"""
        self.driver.get(self.config['base_url'])
        
        start_button = self.wait.until(
            EC.element_to_be_clickable((By.CLASS_NAME, "start-evaluation"))
        )
        start_button.click()
        
        # ç­‰å¾…åˆ†ç±»é¡µé¢åŠ è½½
        self.wait.until(
            EC.presence_of_element_located((By.CLASS_NAME, "categories-grid"))
        )
    
    def take_screenshot(self, name):
        """æˆªå–å±å¹•æˆªå›¾"""
        screenshot_dir = os.path.join(os.path.dirname(__file__), '../screenshots')
        os.makedirs(screenshot_dir, exist_ok=True)
        
        screenshot_path = os.path.join(screenshot_dir, f"{name}.png")
        self.driver.save_screenshot(screenshot_path)
        
        return screenshot_path
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'driver'):
            self.driver.quit()

class PageObject:
    """é¡µé¢å¯¹è±¡åŸºç±»"""
    
    def __init__(self, driver, wait):
        self.driver = driver
        self.wait = wait
    
    def is_loaded(self):
        """æ£€æŸ¥é¡µé¢æ˜¯å¦åŠ è½½å®Œæˆ"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°is_loadedæ–¹æ³•")
    
    def wait_for_page_load(self, timeout=10):
        """ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ"""
        WebDriverWait(self.driver, timeout).until(lambda driver: self.is_loaded())

class EvaluationPage(PageObject):
    """è¯„ä»·é¡µé¢å¯¹è±¡"""
    
    def __init__(self, driver, wait):
        super().__init__(driver, wait)
        self.score_buttons = (By.CSS_SELECTOR, "[data-score]")
        self.evaluator_select = (By.ID, "evaluator-select")
        self.content_editor = (By.ID, "evaluationContent")
        self.submit_button = (By.ID, "submit-evaluation")
    
    def is_loaded(self):
        """æ£€æŸ¥è¯„ä»·é¡µé¢æ˜¯å¦åŠ è½½å®Œæˆ"""
        try:
            self.driver.find_element(*self.submit_button)
            return True
        except:
            return False
    
    def select_score(self, score):
        """é€‰æ‹©è¯„åˆ†"""
        score_button = self.driver.find_element(By.CSS_SELECTOR, f"[data-score='{score}']")
        score_button.click()
    
    def select_evaluator(self, evaluator_name):
        """é€‰æ‹©è¯„ä»·äºº"""
        from selenium.webdriver.support.ui import Select
        
        select_element = self.driver.find_element(*self.evaluator_select)
        select = Select(select_element)
        select.select_by_visible_text(evaluator_name)
    
    def enter_content(self, content):
        """è¾“å…¥è¯„ä»·å†…å®¹"""
        content_element = self.driver.find_element(*self.content_editor)
        content_element.clear()
        content_element.send_keys(content)
    
    def submit_evaluation(self):
        """æäº¤è¯„ä»·"""
        submit_btn = self.driver.find_element(*self.submit_button)
        submit_btn.click()
```

#### 4.4.2 CI/CDé›†æˆ

```yaml
# .github/workflows/test.yml
name: Automated Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=src --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost/test_db

  e2e-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        pip install selenium
    
    - name: Set up Chrome
      uses: browser-actions/setup-chrome@latest
    
    - name: Start application
      run: |
        python app.py &
        sleep 10
      env:
        FLASK_ENV: testing
    
    - name: Run E2E tests
      run: |
        pytest tests/e2e/ -v --html=report.html --self-contained-html
    
    - name: Upload test report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-report
        path: report.html

  performance-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Start application
      run: |
        python app.py &
        sleep 10
      env:
        FLASK_ENV: production
    
    - name: Run performance tests
      run: |
        pytest tests/performance/ -v -s
    
    - name: Performance regression check
      run: |
        python scripts/check_performance_regression.py
```

## 5. è´¨é‡ä¿è¯

### 5.1 è´¨é‡ç›®æ ‡

```yaml
quality_objectives:
  functionality:
    requirement_coverage: ">= 95%"
    feature_completeness: "100%"
    business_rule_compliance: "100%"
  
  reliability:
    mean_time_between_failures: ">= 720 hours"
    defect_density: "<= 1 defect per KLOC"
    system_availability: ">= 99.5%"
  
  performance:
    response_time_p95: "<= 2 seconds"
    throughput: ">= 100 requests/second"
    concurrent_users: ">= 50 users"
  
  security:
    vulnerability_severity_critical: "0"
    vulnerability_severity_high: "<= 2"
    security_test_coverage: "100%"
  
  maintainability:
    code_coverage: ">= 80%"
    cyclomatic_complexity: "<= 10"
    technical_debt_ratio: "<= 5%"
  
  usability:
    task_completion_rate: ">= 95%"
    user_error_rate: "<= 5%"
    user_satisfaction_score: ">= 4.0/5.0"
```

### 5.2 è´¨é‡é—¨ç¦

```mermaid
graph TD
    A[ä»£ç æäº¤] --> B{é™æ€ä»£ç åˆ†æ}
    B -->|é€šè¿‡| C{å•å…ƒæµ‹è¯•}
    B -->|ä¸é€šè¿‡| Z[æ‹’ç»åˆå¹¶]
    C -->|é€šè¿‡| D{ä»£ç è¦†ç›–ç‡æ£€æŸ¥}
    C -->|ä¸é€šè¿‡| Z
    D -->|â‰¥80%| E{é›†æˆæµ‹è¯•}
    D -->|<80%| Z
    E -->|é€šè¿‡| F{å®‰å…¨æ‰«æ}
    E -->|ä¸é€šè¿‡| Z
    F -->|é€šè¿‡| G{æ€§èƒ½æµ‹è¯•}
    F -->|ä¸é€šè¿‡| Z
    G -->|é€šè¿‡| H[å…è®¸åˆå¹¶]
    G -->|ä¸é€šè¿‡| Z
    
    H --> I{éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ}
    I --> J{ç³»ç»Ÿæµ‹è¯•}
    J -->|é€šè¿‡| K{ç”¨æˆ·éªŒæ”¶æµ‹è¯•}
    J -->|ä¸é€šè¿‡| L[ä¿®å¤ç¼ºé™·]
    K -->|é€šè¿‡| M[éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ]
    K -->|ä¸é€šè¿‡| L
    L --> A
```

### 5.3 æµ‹è¯•æŠ¥å‘Š

#### 5.3.1 æµ‹è¯•æ‰§è¡ŒæŠ¥å‘Šæ¨¡æ¿

```markdown
# æµ‹è¯•æ‰§è¡ŒæŠ¥å‘Š

## æŠ¥å‘ŠåŸºæœ¬ä¿¡æ¯
- **é¡¹ç›®åç§°**: è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿ
- **æµ‹è¯•ç‰ˆæœ¬**: v1.0.0
- **æµ‹è¯•ç¯å¢ƒ**: æµ‹è¯•ç¯å¢ƒ
- **æµ‹è¯•å‘¨æœŸ**: 2025-01-15 ~ 2025-01-25
- **æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2025-01-25 18:00
- **æŠ¥å‘Šç¼–å†™äºº**: æµ‹è¯•ç»ç†

## æµ‹è¯•æ¦‚è¿°
æœ¬æ¬¡æµ‹è¯•é’ˆå¯¹è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿv1.0.0ç‰ˆæœ¬è¿›è¡Œå…¨é¢æµ‹è¯•ï¼ŒåŒ…æ‹¬åŠŸèƒ½æµ‹è¯•ã€æ€§èƒ½æµ‹è¯•ã€å®‰å…¨æµ‹è¯•å’Œå…¼å®¹æ€§æµ‹è¯•ã€‚

## æµ‹è¯•æ‰§è¡Œæƒ…å†µ

### æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œç»Ÿè®¡
| æµ‹è¯•ç±»å‹ | è®¡åˆ’ç”¨ä¾‹æ•° | æ‰§è¡Œç”¨ä¾‹æ•° | é€šè¿‡æ•° | å¤±è´¥æ•° | é˜»å¡æ•° | é€šè¿‡ç‡ |
|----------|------------|------------|--------|--------|--------|--------|
| åŠŸèƒ½æµ‹è¯• | 156 | 156 | 148 | 6 | 2 | 94.9% |
| æ€§èƒ½æµ‹è¯• | 12 | 12 | 10 | 2 | 0 | 83.3% |
| å®‰å…¨æµ‹è¯• | 8 | 8 | 8 | 0 | 0 | 100% |
| å…¼å®¹æ€§æµ‹è¯• | 15 | 15 | 13 | 2 | 0 | 86.7% |
| **æ€»è®¡** | **191** | **191** | **179** | **10** | **2** | **93.7%** |

### ä»£ç è¦†ç›–ç‡
- **å•å…ƒæµ‹è¯•è¦†ç›–ç‡**: 85.2%
- **é›†æˆæµ‹è¯•è¦†ç›–ç‡**: 72.8%
- **æ€»ä½“è¦†ç›–ç‡**: 81.5%

### æ€§èƒ½æµ‹è¯•ç»“æœ
| æ€§èƒ½æŒ‡æ ‡ | ç›®æ ‡å€¼ | å®é™…å€¼ | ç»“æœ |
|----------|--------|--------|------|
| é¦–é¡µåŠ è½½æ—¶é—´ | â‰¤ 3s | 1.8s | âœ… é€šè¿‡ |
| APIå“åº”æ—¶é—´(P95) | â‰¤ 2s | 1.2s | âœ… é€šè¿‡ |
| å¹¶å‘ç”¨æˆ·æ•° | â‰¥ 50 | 75 | âœ… é€šè¿‡ |
| ååé‡ | â‰¥ 100 RPS | 120 RPS | âœ… é€šè¿‡ |

## ç¼ºé™·åˆ†æ

### ç¼ºé™·åˆ†å¸ƒ
| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ | ç™¾åˆ†æ¯” |
|----------|------|--------|
| è‡´å‘½ | 0 | 0% |
| ä¸¥é‡ | 2 | 16.7% |
| ä¸€èˆ¬ | 6 | 50% |
| è½»å¾® | 4 | 33.3% |
| **æ€»è®¡** | **12** | **100%** |

### ä¸»è¦ç¼ºé™·
1. **BUG_001** - è¯„ä»·æäº¤åé¡µé¢ç©ºç™½ (ä¸¥é‡)
   - çŠ¶æ€: å·²ä¿®å¤
   - å½±å“: ç”¨æˆ·æ— æ³•æäº¤è¯„ä»·
   
2. **BUG_002** - WordæŠ¥å‘Šä¸­æ–‡å­—ä½“æ˜¾ç¤ºå¼‚å¸¸ (ä¸¥é‡)
   - çŠ¶æ€: å·²ä¿®å¤
   - å½±å“: æŠ¥å‘Šå¯¼å‡ºåŠŸèƒ½å¼‚å¸¸

3. **BUG_003** - iPadæ¨ªå±æ¨¡å¼ä¸‹å¸ƒå±€é”™ä¹± (ä¸€èˆ¬)
   - çŠ¶æ€: ä¿®å¤ä¸­
   - å½±å“: iPadç”¨æˆ·ä½“éªŒ

### ç¼ºé™·è¶‹åŠ¿
[æ’å…¥ç¼ºé™·å‘ç°å’Œä¿®å¤è¶‹åŠ¿å›¾]

## é£é™©è¯„ä¼°

### é«˜é£é™©é¡¹
1. **æ€§èƒ½é£é™©**: åœ¨é«˜å¹¶å‘æƒ…å†µä¸‹å“åº”æ—¶é—´å¯èƒ½è¶…æ ‡
   - å»ºè®®: ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ï¼Œå¢åŠ ç¼“å­˜æœºåˆ¶

2. **å…¼å®¹æ€§é£é™©**: éƒ¨åˆ†æ—§ç‰ˆæœ¬æµè§ˆå™¨å…¼å®¹æ€§é—®é¢˜
   - å»ºè®®: å¢åŠ æµè§ˆå™¨å…¼å®¹æ€§æ£€æŸ¥

### ä¸­é£é™©é¡¹
1. **ç”¨æˆ·ä½“éªŒ**: éƒ¨åˆ†UIäº¤äº’ä¸å¤Ÿç›´è§‚
   - å»ºè®®: è¿›è¡Œå¯ç”¨æ€§æµ‹è¯•ä¼˜åŒ–

## æµ‹è¯•ç»“è®º

### æ€»ä½“è¯„ä»·
ç³»ç»Ÿæ•´ä½“åŠŸèƒ½åŸºæœ¬å®Œæ•´ï¼Œæ ¸å¿ƒä¸šåŠ¡æµç¨‹è¿è¡Œæ­£å¸¸ã€‚æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå®‰å…¨æ€§ç¬¦åˆè¦æ±‚ã€‚å­˜åœ¨å°‘é‡éå…³é”®ç¼ºé™·ï¼Œä¸å½±å“æ­£å¸¸å‘å¸ƒã€‚

### å‘å¸ƒå»ºè®®
- âœ… **å»ºè®®å‘å¸ƒ**: ç³»ç»Ÿè´¨é‡è¾¾åˆ°å‘å¸ƒæ ‡å‡†
- ğŸ“‹ **å‘å¸ƒæ¡ä»¶**: 
  1. ä¸¥é‡ç¼ºé™·å·²å…¨éƒ¨ä¿®å¤
  2. æ€§èƒ½æµ‹è¯•é€šè¿‡
  3. å®‰å…¨æµ‹è¯•æ— é«˜å±æ¼æ´

### åç»­å»ºè®®
1. ç»§ç»­å®Œå–„è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ç‡
2. åŠ å¼ºæ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
3. å®šæœŸè¿›è¡Œå®‰å…¨æ¼æ´æ‰«æ
4. æ”¶é›†ç”¨æˆ·åé¦ˆæŒç»­æ”¹è¿›

## é™„å½•
- è¯¦ç»†æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œè®°å½•
- ç¼ºé™·æŠ¥å‘Šæ¸…å•
- æ€§èƒ½æµ‹è¯•è¯¦ç»†æ•°æ®
- è‡ªåŠ¨åŒ–æµ‹è¯•æŠ¥å‘Š
```

## 6. æ€»ç»“

### 6.1 æµ‹è¯•è§„èŒƒä¼˜åŠ¿

1. **å…¨é¢è¦†ç›–**: ä»å•å…ƒæµ‹è¯•åˆ°éªŒæ”¶æµ‹è¯•çš„å®Œæ•´æµ‹è¯•ä½“ç³»
2. **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜**: å¤§éƒ¨åˆ†æµ‹è¯•å®ç°è‡ªåŠ¨åŒ–æ‰§è¡Œ
3. **è´¨é‡ä¿è¯**: ä¸¥æ ¼çš„è´¨é‡é—¨ç¦å’Œè¯„ä¼°æ ‡å‡†
4. **æŒç»­æ”¹è¿›**: åŸºäºæ•°æ®é©±åŠ¨çš„è´¨é‡æ”¹è¿›æµç¨‹
5. **å›¢é˜Ÿåä½œ**: æ˜ç¡®çš„è§’è‰²åˆ†å·¥å’Œåä½œæµç¨‹

### 6.2 æµ‹è¯•å·¥å…·é“¾

- **å•å…ƒæµ‹è¯•**: pytest + coverage
- **APIæµ‹è¯•**: requests + pytest
- **UIæµ‹è¯•**: Selenium + pytest
- **æ€§èƒ½æµ‹è¯•**: Apache Bench + custom scripts
- **å®‰å…¨æµ‹è¯•**: bandit + safety
- **ä»£ç è´¨é‡**: flake8 + mypy + black
- **CI/CD**: GitHub Actions
- **æŠ¥å‘Šç”Ÿæˆ**: pytest-html + allure

### 6.3 æŒç»­æ”¹è¿›è®¡åˆ’

**çŸ­æœŸæ”¹è¿›**:
- å®Œå–„æµ‹è¯•ç”¨ä¾‹è¦†ç›–ç‡
- ä¼˜åŒ–è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œæ•ˆç‡
- å¢å¼ºæ€§èƒ½æµ‹è¯•åœºæ™¯

**ä¸­æœŸæ”¹è¿›**:
- å¼•å…¥AIè¾…åŠ©æµ‹è¯•ç”Ÿæˆ
- å»ºè®¾å¯è§†åŒ–æµ‹è¯•æŠ¥å‘Š
- å®ç°æµ‹è¯•æ•°æ®ç®¡ç†å¹³å°

**é•¿æœŸæ”¹è¿›**:
- æ„å»ºæ™ºèƒ½ç¼ºé™·é¢„æµ‹ç³»ç»Ÿ
- å®ç°å…¨é“¾è·¯è´¨é‡è¿½è¸ª
- å»ºè®¾è´¨é‡å¤§æ•°æ®åˆ†æå¹³å°

---
**æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆ  
**æœ€åæ›´æ–°**: 2025å¹´7æœˆ23æ—¥  
**ç‰ˆæœ¬å·**: 1.0