# è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿæ—¥å¿—å’Œç›‘æ§è®¾è®¡æ–‡æ¡£

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** 1.0  
**ç¼–å†™æ—¥æœŸï¼š** 2025å¹´7æœˆ23æ—¥  
**ç¼–å†™äººå‘˜ï¼š** è¿ç»´æ¶æ„å¸ˆ  
**å®¡æ ¸äººå‘˜ï¼š** ç³»ç»Ÿæ¶æ„å¸ˆ  

## 1. å¼•è¨€

### 1.1 ç¼–å†™ç›®çš„
æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†è¯•è½¦åé¦ˆè¯„ä»·ç³»ç»Ÿçš„æ—¥å¿—è®°å½•ç­–ç•¥ã€ç›‘æ§æœºåˆ¶ã€å‘Šè­¦ä½“ç³»å’Œè¿ç»´æ”¯æ’‘æ–¹æ¡ˆï¼Œä¸ºç³»ç»Ÿè¿ç»´ã€æ•…éšœæ’æŸ¥å’Œæ€§èƒ½ä¼˜åŒ–æä¾›å®Œæ•´æŒ‡å¯¼ã€‚

### 1.2 è®¾è®¡ç›®æ ‡
- **å…¨é¢æ€§**: è¦†ç›–åº”ç”¨ã€ç³»ç»Ÿã€å®‰å…¨ç­‰å„ä¸ªå±‚é¢çš„æ—¥å¿—å’Œç›‘æ§
- **å®æ—¶æ€§**: æä¾›å®æ—¶ç›‘æ§å’Œå¿«é€Ÿå“åº”èƒ½åŠ›
- **å¯è§‚æµ‹æ€§**: é€šè¿‡æ—¥å¿—ã€æŒ‡æ ‡ã€é“¾è·¯è¿½è¸ªå®ç°ç³»ç»Ÿå¯è§‚æµ‹æ€§
- **è‡ªåŠ¨åŒ–**: è‡ªåŠ¨åŒ–å‘Šè­¦ã€æ•…éšœè¯Šæ–­å’Œæ¢å¤æœºåˆ¶
- **æ ‡å‡†åŒ–**: ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼å’Œç›‘æ§æ ‡å‡†

### 1.3 æŠ€æœ¯æ¶æ„
- **æ—¥å¿—ç³»ç»Ÿ**: Python logging + ç»“æ„åŒ–æ—¥å¿—
- **ç›‘æ§ç³»ç»Ÿ**: Prometheus + Grafana
- **å‘Šè­¦ç³»ç»Ÿ**: AlertManager + é‚®ä»¶/Webhook
- **é“¾è·¯è¿½è¸ª**: OpenTelemetry
- **æ—¥å¿—èšåˆ**: ELK Stack (å¯é€‰)

## 2. æ—¥å¿—ç³»ç»Ÿè®¾è®¡

### 2.1 æ—¥å¿—åˆ†ç±»ä½“ç³»

```mermaid
graph TB
    subgraph "æ—¥å¿—åˆ†ç±»"
        A[åº”ç”¨æ—¥å¿—]
        B[ç³»ç»Ÿæ—¥å¿—]
        C[å®‰å…¨æ—¥å¿—]
        D[è®¿é—®æ—¥å¿—]
        E[æ€§èƒ½æ—¥å¿—]
        F[é”™è¯¯æ—¥å¿—]
    end
    
    subgraph "æ—¥å¿—çº§åˆ«"
        G[DEBUG]
        H[INFO]
        I[WARNING]
        J[ERROR]
        K[CRITICAL]
    end
    
    subgraph "å­˜å‚¨æ–¹å¼"
        L[æ–‡ä»¶å­˜å‚¨]
        M[æ•°æ®åº“å­˜å‚¨]
        N[è¿œç¨‹å­˜å‚¨]
    end
    
    A --> H
    A --> I
    B --> H
    B --> J
    C --> I
    C --> J
    D --> H
    E --> H
    F --> J
    F --> K
    
    H --> L
    I --> L
    J --> L
    J --> M
    K --> M
    K --> N
```

### 2.2 æ—¥å¿—é…ç½®è®¾è®¡

#### 2.2.1 Python Loggingé…ç½®

```python
import logging
import logging.handlers
import json
import os
from datetime import datetime
import traceback
from pythonjsonlogger import jsonlogger

class EvaluationSystemLogger:
    """è¯„ä»·ç³»ç»Ÿæ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self, app_name="evaluation-system", log_dir="/var/log/evaluation-system"):
        self.app_name = app_name
        self.log_dir = log_dir
        self.ensure_log_directory()
        self.setup_loggers()
    
    def ensure_log_directory(self):
        """ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨"""
        os.makedirs(self.log_dir, exist_ok=True)
        
        # è®¾ç½®ç›®å½•æƒé™
        os.chmod(self.log_dir, 0o755)
    
    def setup_loggers(self):
        """è®¾ç½®å„ç§æ—¥å¿—è®°å½•å™¨"""
        
        # 1. åº”ç”¨ä¸»æ—¥å¿—
        self.app_logger = self._create_logger(
            name='evaluation.app',
            filename=f'{self.log_dir}/application.log',
            level=logging.INFO,
            max_bytes=50*1024*1024,  # 50MB
            backup_count=10
        )
        
        # 2. é”™è¯¯æ—¥å¿—
        self.error_logger = self._create_logger(
            name='evaluation.error',
            filename=f'{self.log_dir}/error.log',
            level=logging.ERROR,
            max_bytes=20*1024*1024,  # 20MB
            backup_count=15
        )
        
        # 3. å®‰å…¨æ—¥å¿—
        self.security_logger = self._create_logger(
            name='evaluation.security',
            filename=f'{self.log_dir}/security.log',
            level=logging.INFO,
            max_bytes=30*1024*1024,  # 30MB
            backup_count=20
        )
        
        # 4. æ€§èƒ½æ—¥å¿—
        self.performance_logger = self._create_logger(
            name='evaluation.performance',
            filename=f'{self.log_dir}/performance.log',
            level=logging.INFO,
            max_bytes=100*1024*1024,  # 100MB
            backup_count=5
        )
        
        # 5. å®¡è®¡æ—¥å¿—
        self.audit_logger = self._create_logger(
            name='evaluation.audit',
            filename=f'{self.log_dir}/audit.log',
            level=logging.INFO,
            max_bytes=200*1024*1024,  # 200MB
            backup_count=30  # ä¿ç•™æ›´é•¿æ—¶é—´
        )
    
    def _create_logger(self, name, filename, level, max_bytes, backup_count):
        """åˆ›å»ºæ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(name)
        logger.setLevel(level)
        
        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
        if logger.handlers:
            return logger
        
        # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰
        file_handler = logging.handlers.RotatingFileHandler(
            filename=filename,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )
        
        # JSONæ ¼å¼åŒ–å™¨
        json_formatter = jsonlogger.JsonFormatter(
            fmt='%(asctime)s %(name)s %(levelname)s %(message)s %(pathname)s %(lineno)d',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(json_formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        if os.environ.get('FLASK_ENV') == 'development':
            console_handler = logging.StreamHandler()
            console_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)
        
        logger.addHandler(file_handler)
        return logger
    
    def get_logger(self, logger_type='app'):
        """è·å–æŒ‡å®šç±»å‹çš„æ—¥å¿—è®°å½•å™¨"""
        loggers = {
            'app': self.app_logger,
            'error': self.error_logger,
            'security': self.security_logger,
            'performance': self.performance_logger,
            'audit': self.audit_logger
        }
        return loggers.get(logger_type, self.app_logger)

# å…¨å±€æ—¥å¿—ç®¡ç†å™¨å®ä¾‹
log_manager = EvaluationSystemLogger()
```

#### 2.2.2 ç»“æ„åŒ–æ—¥å¿—æ ¼å¼

```python
import json
from datetime import datetime
from flask import request, g
import uuid

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, logger_manager):
        self.logger_manager = logger_manager
    
    def log_application_event(self, event_type, message, **kwargs):
        """è®°å½•åº”ç”¨äº‹ä»¶"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'event_type': event_type,
            'message': message,
            'request_id': self._get_request_id(),
            'user_id': self._get_user_id(),
            'session_id': self._get_session_id(),
            'remote_addr': self._get_remote_addr(),
            'user_agent': self._get_user_agent(),
            'extra_data': kwargs
        }
        
        logger = self.logger_manager.get_logger('app')
        logger.info(json.dumps(log_data, ensure_ascii=False))
    
    def log_error(self, error, context=None):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback.format_exc(),
            'request_id': self._get_request_id(),
            'user_id': self._get_user_id(),
            'request_url': getattr(request, 'url', None),
            'request_method': getattr(request, 'method', None),
            'context': context or {}
        }
        
        logger = self.logger_manager.get_logger('error')
        logger.error(json.dumps(log_data, ensure_ascii=False))
    
    def log_security_event(self, event_type, severity='INFO', details=None):
        """è®°å½•å®‰å…¨äº‹ä»¶"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'event_type': event_type,
            'severity': severity,
            'user_id': self._get_user_id(),
            'remote_addr': self._get_remote_addr(),
            'user_agent': self._get_user_agent(),
            'request_url': getattr(request, 'url', None),
            'session_id': self._get_session_id(),
            'details': details or {}
        }
        
        logger = self.logger_manager.get_logger('security')
        if severity == 'CRITICAL':
            logger.critical(json.dumps(log_data, ensure_ascii=False))
        elif severity == 'ERROR':
            logger.error(json.dumps(log_data, ensure_ascii=False))
        elif severity == 'WARNING':
            logger.warning(json.dumps(log_data, ensure_ascii=False))
        else:
            logger.info(json.dumps(log_data, ensure_ascii=False))
    
    def log_performance_metric(self, metric_name, value, unit='ms', **tags):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'metric_name': metric_name,
            'value': value,
            'unit': unit,
            'request_id': self._get_request_id(),
            'endpoint': getattr(request, 'endpoint', None),
            'method': getattr(request, 'method', None),
            'tags': tags
        }
        
        logger = self.logger_manager.get_logger('performance')
        logger.info(json.dumps(log_data, ensure_ascii=False))
    
    def log_audit_event(self, action, resource_type, resource_id, old_values=None, new_values=None):
        """è®°å½•å®¡è®¡äº‹ä»¶"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'action': action,  # CREATE, READ, UPDATE, DELETE
            'resource_type': resource_type,  # evaluation, vehicle, activity, etc.
            'resource_id': resource_id,
            'user_id': self._get_user_id(),
            'session_id': self._get_session_id(),
            'remote_addr': self._get_remote_addr(),
            'old_values': old_values,
            'new_values': new_values,
            'request_id': self._get_request_id()
        }
        
        logger = self.logger_manager.get_logger('audit')
        logger.info(json.dumps(log_data, ensure_ascii=False))
    
    def _get_request_id(self):
        """è·å–è¯·æ±‚ID"""
        if hasattr(g, 'request_id'):
            return g.request_id
        return str(uuid.uuid4())
    
    def _get_user_id(self):
        """è·å–ç”¨æˆ·ID"""
        from flask_login import current_user
        if current_user and current_user.is_authenticated:
            return current_user.id
        return None
    
    def _get_session_id(self):
        """è·å–ä¼šè¯ID"""
        from flask import session
        return session.get('session_id', None)
    
    def _get_remote_addr(self):
        """è·å–å®¢æˆ·ç«¯IP"""
        return getattr(request, 'remote_addr', None)
    
    def _get_user_agent(self):
        """è·å–ç”¨æˆ·ä»£ç†"""
        return getattr(request, 'headers', {}).get('User-Agent', None)

# å…¨å±€ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨
structured_logger = StructuredLogger(log_manager)
```

### 2.3 æ—¥å¿—ä¸­é—´ä»¶å’Œè£…é¥°å™¨

#### 2.3.1 Flaskè¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶

```python
from functools import wraps
import time
from flask import request, g
import uuid

def setup_request_logging(app):
    """è®¾ç½®è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶"""
    
    @app.before_request
    def before_request():
        """è¯·æ±‚å¼€å§‹æ—¶çš„å¤„ç†"""
        # ç”Ÿæˆè¯·æ±‚ID
        g.request_id = str(uuid.uuid4())
        g.start_time = time.time()
        
        # è®°å½•è¯·æ±‚å¼€å§‹
        structured_logger.log_application_event(
            event_type='request_start',
            message=f'{request.method} {request.url}',
            request_method=request.method,
            request_url=request.url,
            request_headers=dict(request.headers),
            request_args=dict(request.args)
        )
    
    @app.after_request
    def after_request(response):
        """è¯·æ±‚ç»“æŸæ—¶çš„å¤„ç†"""
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (time.time() - g.start_time) * 1000  # æ¯«ç§’
        
        # è®°å½•è¯·æ±‚ç»“æŸ
        structured_logger.log_application_event(
            event_type='request_end',
            message=f'{request.method} {request.url} - {response.status_code}',
            request_method=request.method,
            request_url=request.url,
            response_status=response.status_code,
            processing_time_ms=processing_time
        )
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        structured_logger.log_performance_metric(
            metric_name='request_duration',
            value=processing_time,
            unit='ms',
            method=request.method,
            endpoint=request.endpoint,
            status_code=response.status_code
        )
        
        # æ…¢è¯·æ±‚å‘Šè­¦
        if processing_time > 5000:  # è¶…è¿‡5ç§’
            structured_logger.log_application_event(
                event_type='slow_request',
                message=f'Slow request detected: {processing_time:.2f}ms',
                processing_time_ms=processing_time,
                request_url=request.url
            )
        
        return response
    
    @app.errorhandler(Exception)
    def handle_exception(error):
        """å…¨å±€å¼‚å¸¸å¤„ç†"""
        structured_logger.log_error(
            error=error,
            context={
                'request_method': request.method,
                'request_url': request.url,
                'request_args': dict(request.args),
                'request_form': dict(request.form) if request.form else None
            }
        )
        
        # è¿”å›é”™è¯¯å“åº”
        return {
            'error': 'Internal server error',
            'request_id': g.request_id
        }, 500

def log_function_execution(logger_type='app'):
    """å‡½æ•°æ‰§è¡Œæ—¥å¿—è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            func_name = f"{func.__module__}.{func.__name__}"
            start_time = time.time()
            
            try:
                # è®°å½•å‡½æ•°å¼€å§‹æ‰§è¡Œ
                structured_logger.log_application_event(
                    event_type='function_start',
                    message=f'Function {func_name} started',
                    function_name=func_name,
                    args_count=len(args),
                    kwargs_keys=list(kwargs.keys())
                )
                
                result = func(*args, **kwargs)
                
                # è®°å½•å‡½æ•°æ‰§è¡ŒæˆåŠŸ
                execution_time = (time.time() - start_time) * 1000
                structured_logger.log_application_event(
                    event_type='function_success',
                    message=f'Function {func_name} completed',
                    function_name=func_name,
                    execution_time_ms=execution_time
                )
                
                return result
                
            except Exception as e:
                # è®°å½•å‡½æ•°æ‰§è¡Œé”™è¯¯
                execution_time = (time.time() - start_time) * 1000
                structured_logger.log_error(
                    error=e,
                    context={
                        'function_name': func_name,
                        'execution_time_ms': execution_time,
                        'args_count': len(args),
                        'kwargs': kwargs
                    }
                )
                raise
        return wrapper
    return decorator

def log_database_operations():
    """æ•°æ®åº“æ“ä½œæ—¥å¿—è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            operation_start = time.time()
            
            try:
                result = func(*args, **kwargs)
                
                # è®°å½•æˆåŠŸçš„æ•°æ®åº“æ“ä½œ
                execution_time = (time.time() - operation_start) * 1000
                structured_logger.log_performance_metric(
                    metric_name='database_operation_duration',
                    value=execution_time,
                    unit='ms',
                    operation=func.__name__,
                    success=True
                )
                
                return result
                
            except Exception as e:
                # è®°å½•å¤±è´¥çš„æ•°æ®åº“æ“ä½œ
                execution_time = (time.time() - operation_start) * 1000
                structured_logger.log_error(
                    error=e,
                    context={
                        'operation': func.__name__,
                        'execution_time_ms': execution_time,
                        'operation_type': 'database'
                    }
                )
                
                structured_logger.log_performance_metric(
                    metric_name='database_operation_duration',
                    value=execution_time,
                    unit='ms',
                    operation=func.__name__,
                    success=False
                )
                raise
                
        return wrapper
    return decorator
```

## 3. ç›‘æ§ç³»ç»Ÿè®¾è®¡

### 3.1 ç›‘æ§æ¶æ„

```mermaid
graph TB
    subgraph "æ•°æ®é‡‡é›†å±‚"
        A[Flaskåº”ç”¨æŒ‡æ ‡]
        B[ç³»ç»Ÿèµ„æºæŒ‡æ ‡]
        C[æ•°æ®åº“æŒ‡æ ‡]
        D[è‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡]
    end
    
    subgraph "å­˜å‚¨å’Œå¤„ç†å±‚"
        E[Prometheus Server]
        F[æ—¶åºæ•°æ®åº“]
        G[æŒ‡æ ‡èšåˆ]
    end
    
    subgraph "å±•ç¤ºå±‚"
        H[Grafana Dashboard]
        I[ç›‘æ§å¤§å±]
        J[ç§»åŠ¨ç«¯ç›‘æ§]
    end
    
    subgraph "å‘Šè­¦å±‚"
        K[AlertManager]
        L[é‚®ä»¶å‘Šè­¦]
        M[Webhookå‘Šè­¦]
        N[çŸ­ä¿¡å‘Šè­¦]
    end
    
    A --> E
    B --> E
    C --> E
    D --> E
    
    E --> F
    E --> G
    
    F --> H
    G --> H
    H --> I
    H --> J
    
    E --> K
    K --> L
    K --> M
    K --> N
```

### 3.2 æŒ‡æ ‡é‡‡é›†è®¾è®¡

#### 3.2.1 åº”ç”¨æŒ‡æ ‡é‡‡é›†

```python
import time
from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry, generate_latest
from flask import Response
import psutil
import sqlite3

class EvaluationSystemMetrics:
    """è¯„ä»·ç³»ç»ŸæŒ‡æ ‡é‡‡é›†å™¨"""
    
    def __init__(self):
        self.registry = CollectorRegistry()
        self.setup_metrics()
    
    def setup_metrics(self):
        """è®¾ç½®ç›‘æ§æŒ‡æ ‡"""
        
        # 1. HTTPè¯·æ±‚æŒ‡æ ‡
        self.http_requests_total = Counter(
            'http_requests_total',
            'Total HTTP requests',
            ['method', 'endpoint', 'status_code'],
            registry=self.registry
        )
        
        self.http_request_duration = Histogram(
            'http_request_duration_seconds',
            'HTTP request duration in seconds',
            ['method', 'endpoint'],
            registry=self.registry,
            buckets=(0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)
        )
        
        # 2. æ•°æ®åº“æŒ‡æ ‡
        self.db_operations_total = Counter(
            'db_operations_total',
            'Total database operations',
            ['operation', 'table', 'status'],
            registry=self.registry
        )
        
        self.db_operation_duration = Histogram(
            'db_operation_duration_seconds',
            'Database operation duration in seconds',
            ['operation', 'table'],
            registry=self.registry
        )
        
        self.db_connections_active = Gauge(
            'db_connections_active',
            'Active database connections',
            registry=self.registry
        )
        
        # 3. ä¸šåŠ¡æŒ‡æ ‡
        self.evaluations_total = Counter(
            'evaluations_total',
            'Total evaluations created',
            ['category', 'activity_id'],
            registry=self.registry
        )
        
        self.users_active = Gauge(
            'users_active',
            'Currently active users',
            registry=self.registry
        )
        
        self.evaluations_score_distribution = Histogram(
            'evaluations_score_distribution',
            'Distribution of evaluation scores',
            registry=self.registry,
            buckets=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
        )
        
        # 4. ç³»ç»Ÿèµ„æºæŒ‡æ ‡
        self.system_cpu_usage = Gauge(
            'system_cpu_usage_percent',
            'System CPU usage percentage',
            registry=self.registry
        )
        
        self.system_memory_usage = Gauge(
            'system_memory_usage_bytes',
            'System memory usage in bytes',
            registry=self.registry
        )
        
        self.system_disk_usage = Gauge(
            'system_disk_usage_percent',
            'System disk usage percentage',
            ['mount_point'],
            registry=self.registry
        )
        
        # 5. é”™è¯¯æŒ‡æ ‡
        self.errors_total = Counter(
            'errors_total',
            'Total application errors',
            ['error_type', 'severity'],
            registry=self.registry
        )
        
        self.security_events_total = Counter(
            'security_events_total',
            'Total security events',
            ['event_type', 'severity'],
            registry=self.registry
        )
    
    def record_http_request(self, method, endpoint, status_code, duration):
        """è®°å½•HTTPè¯·æ±‚æŒ‡æ ‡"""
        self.http_requests_total.labels(
            method=method,
            endpoint=endpoint,
            status_code=status_code
        ).inc()
        
        self.http_request_duration.labels(
            method=method,
            endpoint=endpoint
        ).observe(duration)
    
    def record_db_operation(self, operation, table, duration, success=True):
        """è®°å½•æ•°æ®åº“æ“ä½œæŒ‡æ ‡"""
        status = 'success' if success else 'error'
        
        self.db_operations_total.labels(
            operation=operation,
            table=table,
            status=status
        ).inc()
        
        self.db_operation_duration.labels(
            operation=operation,
            table=table
        ).observe(duration)
    
    def record_evaluation_created(self, category, activity_id, score):
        """è®°å½•è¯„ä»·åˆ›å»ºæŒ‡æ ‡"""
        self.evaluations_total.labels(
            category=category,
            activity_id=str(activity_id)
        ).inc()
        
        self.evaluations_score_distribution.observe(score)
    
    def record_error(self, error_type, severity='error'):
        """è®°å½•é”™è¯¯æŒ‡æ ‡"""
        self.errors_total.labels(
            error_type=error_type,
            severity=severity
        ).inc()
    
    def record_security_event(self, event_type, severity='info'):
        """è®°å½•å®‰å…¨äº‹ä»¶æŒ‡æ ‡"""
        self.security_events_total.labels(
            event_type=event_type,
            severity=severity
        ).inc()
    
    def update_system_metrics(self):
        """æ›´æ–°ç³»ç»Ÿèµ„æºæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        self.system_cpu_usage.set(cpu_percent)
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        self.system_memory_usage.set(memory.used)
        
        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        for disk in psutil.disk_partitions():
            try:
                usage = psutil.disk_usage(disk.mountpoint)
                self.system_disk_usage.labels(
                    mount_point=disk.mountpoint
                ).set(usage.percent)
            except PermissionError:
                continue
    
    def get_metrics(self):
        """è·å–æ‰€æœ‰æŒ‡æ ‡æ•°æ®"""
        self.update_system_metrics()
        return generate_latest(self.registry)

# å…¨å±€æŒ‡æ ‡é‡‡é›†å™¨
metrics_collector = EvaluationSystemMetrics()

# Flaskè·¯ç”±æš´éœ²æŒ‡æ ‡
@app.route('/metrics')
def metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    return Response(
        metrics_collector.get_metrics(),
        mimetype='text/plain'
    )
```

#### 3.2.2 æŒ‡æ ‡ä¸­é—´ä»¶é›†æˆ

```python
def setup_metrics_middleware(app, metrics_collector):
    """è®¾ç½®æŒ‡æ ‡é‡‡é›†ä¸­é—´ä»¶"""
    
    @app.before_request
    def before_request_metrics():
        g.start_time = time.time()
    
    @app.after_request
    def after_request_metrics(response):
        # è®¡ç®—è¯·æ±‚å¤„ç†æ—¶é—´
        duration = time.time() - g.start_time
        
        # è®°å½•HTTPè¯·æ±‚æŒ‡æ ‡
        metrics_collector.record_http_request(
            method=request.method,
            endpoint=request.endpoint or 'unknown',
            status_code=response.status_code,
            duration=duration
        )
        
        return response
    
    @app.errorhandler(Exception)
    def error_handler_metrics(error):
        # è®°å½•é”™è¯¯æŒ‡æ ‡
        metrics_collector.record_error(
            error_type=type(error).__name__,
            severity='critical' if hasattr(error, 'code') and error.code >= 500 else 'error'
        )
        
        return {'error': 'Internal server error'}, 500

# æ•°æ®åº“æ“ä½œæŒ‡æ ‡è£…é¥°å™¨
def monitor_db_operation(operation, table):
    """æ•°æ®åº“æ“ä½œç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            success = True
            
            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                success = False
                raise
            finally:
                duration = time.time() - start_time
                metrics_collector.record_db_operation(
                    operation=operation,
                    table=table,
                    duration=duration,
                    success=success
                )
        return wrapper
    return decorator

# ä¸šåŠ¡æŒ‡æ ‡è®°å½•å‡½æ•°
def record_business_metric(metric_type, **labels):
    """è®°å½•ä¸šåŠ¡æŒ‡æ ‡"""
    if metric_type == 'evaluation_created':
        metrics_collector.record_evaluation_created(
            category=labels.get('category'),
            activity_id=labels.get('activity_id'),
            score=labels.get('score')
        )
    elif metric_type == 'user_login':
        # æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æ´»è·ƒç”¨æˆ·ç»Ÿè®¡é€»è¾‘
        pass
```

### 3.3 Grafanaä»ªè¡¨æ¿é…ç½®

#### 3.3.1 ç³»ç»Ÿæ¦‚è§ˆä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "è¯•è½¦è¯„ä»·ç³»ç»Ÿ - ç³»ç»Ÿæ¦‚è§ˆ",
    "tags": ["evaluation-system", "overview"],
    "panels": [
      {
        "title": "HTTPè¯·æ±‚ç»Ÿè®¡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "yAxes": [
          {
            "label": "è¯·æ±‚/ç§’"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´åˆ†å¸ƒ",
        "type": "heatmap",
        "targets": [
          {
            "expr": "rate(http_request_duration_seconds_bucket[5m])",
            "legendFormat": "{{le}}"
          }
        ]
      },
      {
        "title": "é”™è¯¯ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status_code=~\"4..|5..\"}[5m]) / rate(http_requests_total[5m]) * 100",
            "legendFormat": "é”™è¯¯ç‡ %"
          }
        ],
        "thresholds": [
          {"color": "green", "value": 0},
          {"color": "yellow", "value": 1},
          {"color": "red", "value": 5}
        ]
      },
      {
        "title": "ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ",
        "type": "graph",
        "targets": [
          {
            "expr": "system_cpu_usage_percent",
            "legendFormat": "CPUä½¿ç”¨ç‡ %"
          },
          {
            "expr": "system_memory_usage_bytes / 1024 / 1024",
            "legendFormat": "å†…å­˜ä½¿ç”¨ MB"
          }
        ]
      }
    ]
  }
}
```

#### 3.3.2 ä¸šåŠ¡ç›‘æ§ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "è¯•è½¦è¯„ä»·ç³»ç»Ÿ - ä¸šåŠ¡ç›‘æ§",
    "tags": ["evaluation-system", "business"],
    "panels": [
      {
        "title": "è¯„ä»·åˆ›å»ºè¶‹åŠ¿",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(evaluations_total[1h])",
            "legendFormat": "{{category}}"
          }
        ]
      },
      {
        "title": "è¯„åˆ†åˆ†å¸ƒ",
        "type": "histogram",
        "targets": [
          {
            "expr": "evaluations_score_distribution",
            "legendFormat": "è¯„åˆ†{{le}}"
          }
        ]
      },
      {
        "title": "æ´»è·ƒç”¨æˆ·æ•°",
        "type": "stat",
        "targets": [
          {
            "expr": "users_active",
            "legendFormat": "å½“å‰æ´»è·ƒç”¨æˆ·"
          }
        ]
      },
      {
        "title": "æ•°æ®åº“æ“ä½œæ€§èƒ½",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(db_operations_total[5m])",
            "legendFormat": "{{operation}} {{table}}"
          }
        ]
      }
    ]
  }
}
```

## 4. å‘Šè­¦ç³»ç»Ÿè®¾è®¡

### 4.1 å‘Šè­¦è§„åˆ™é…ç½®

#### 4.1.1 Prometheuså‘Šè­¦è§„åˆ™

```yaml
# evaluation-system-alerts.yml
groups:
  - name: evaluation-system-alerts
    rules:
      # ç³»ç»Ÿçº§åˆ«å‘Šè­¦
      - alert: HighCPUUsage
        expr: system_cpu_usage_percent > 80
        for: 5m
        labels:
          severity: warning
          service: evaluation-system
        annotations:
          summary: "ç³»ç»ŸCPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "CPUä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%ï¼ŒæŒç»­5åˆ†é’Ÿ"
      
      - alert: HighMemoryUsage
        expr: system_memory_usage_bytes / (1024*1024*1024) > 2
        for: 5m
        labels:
          severity: warning
          service: evaluation-system
        annotations:
          summary: "ç³»ç»Ÿå†…å­˜ä½¿ç”¨è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨å·²è¾¾åˆ° {{ $value }}GB"
      
      - alert: DiskSpaceAlert
        expr: system_disk_usage_percent > 85
        for: 2m
        labels:
          severity: critical
          service: evaluation-system
        annotations:
          summary: "ç£ç›˜ç©ºé—´ä¸è¶³"
          description: "ç£ç›˜ {{ $labels.mount_point }} ä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%"
      
      # åº”ç”¨çº§åˆ«å‘Šè­¦
      - alert: HighErrorRate
        expr: rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 3m
        labels:
          severity: critical
          service: evaluation-system
        annotations:
          summary: "HTTPé”™è¯¯ç‡è¿‡é«˜"
          description: "5xxé”™è¯¯ç‡å·²è¾¾åˆ° {{ $value | humanizePercentage }}"
      
      - alert: SlowResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
          service: evaluation-system
        annotations:
          summary: "å“åº”æ—¶é—´è¿‡æ…¢"
          description: "95%çš„è¯·æ±‚å“åº”æ—¶é—´è¶…è¿‡5ç§’"
      
      - alert: DatabaseConnectionIssue
        expr: db_connections_active > 15
        for: 2m
        labels:
          severity: warning
          service: evaluation-system
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡å¤š"
          description: "å½“å‰æ´»è·ƒæ•°æ®åº“è¿æ¥æ•°: {{ $value }}"
      
      # ä¸šåŠ¡çº§åˆ«å‘Šè­¦
      - alert: NoEvaluationsCreated
        expr: increase(evaluations_total[1h]) == 0
        for: 1h
        labels:
          severity: warning
          service: evaluation-system
        annotations:
          summary: "é•¿æ—¶é—´æ— è¯„ä»·åˆ›å»º"
          description: "è¿‡å»1å°æ—¶å†…æ²¡æœ‰æ–°çš„è¯„ä»·åˆ›å»º"
      
      - alert: SecurityEventSpike
        expr: increase(security_events_total{severity="critical"}[10m]) > 5
        for: 0m
        labels:
          severity: critical
          service: evaluation-system
        annotations:
          summary: "å®‰å…¨äº‹ä»¶æ¿€å¢"
          description: "10åˆ†é’Ÿå†…å‘ç”Ÿäº† {{ $value }} æ¬¡ä¸¥é‡å®‰å…¨äº‹ä»¶"
      
      # ç³»ç»Ÿå¥åº·æ£€æŸ¥
      - alert: ServiceDown
        expr: up{job="evaluation-system"} == 0
        for: 1m
        labels:
          severity: critical
          service: evaluation-system
        annotations:
          summary: "æœåŠ¡ä¸å¯ç”¨"
          description: "è¯„ä»·ç³»ç»ŸæœåŠ¡å·²åœæ­¢å“åº”"
```

#### 4.1.2 AlertManageré…ç½®

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@company.com'
  smtp_auth_username: 'alerts@company.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname', 'service']
  group_wait: 10s
  group_interval: 30s
  repeat_interval: 12h
  receiver: 'default-receiver'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 5s
      repeat_interval: 5m
    - match:
        severity: warning
      receiver: 'warning-alerts'
      repeat_interval: 1h

receivers:
  - name: 'default-receiver'
    email_configs:
      - to: 'ops-team@company.com'
        subject: '[ALERT] {{ .GroupLabels.service }} - {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          å‘Šè­¦åç§°: {{ .Annotations.summary }}
          å‘Šè­¦æè¿°: {{ .Annotations.description }}
          å‘Šè­¦æ—¶é—´: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          å‘Šè­¦æ ‡ç­¾: {{ .Labels }}
          
          {{ end }}
  
  - name: 'critical-alerts'
    email_configs:
      - to: 'ops-team@company.com,manager@company.com'
        subject: '[CRITICAL] {{ .GroupLabels.service }} - {{ .GroupLabels.alertname }}'
        body: |
          ğŸš¨ ä¸¥é‡å‘Šè­¦ ğŸš¨
          
          {{ range .Alerts }}
          å‘Šè­¦åç§°: {{ .Annotations.summary }}
          å‘Šè­¦æè¿°: {{ .Annotations.description }}
          å‘Šè­¦æ—¶é—´: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          æœåŠ¡: {{ .Labels.service }}
          
          è¯·ç«‹å³å¤„ç†ï¼
          {{ end }}
    
    webhook_configs:
      - url: 'http://localhost:5000/webhook/alerts'
        send_resolved: true
  
  - name: 'warning-alerts'
    email_configs:
      - to: 'ops-team@company.com'
        subject: '[WARNING] {{ .GroupLabels.service }} - {{ .GroupLabels.alertname }}'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'service']
```

### 4.2 è‡ªå®šä¹‰å‘Šè­¦å¤„ç†

#### 4.2.1 å‘Šè­¦Webhookå¤„ç†å™¨

```python
from flask import request, jsonify
import json
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import requests

class AlertHandler:
    """å‘Šè­¦å¤„ç†å™¨"""
    
    def __init__(self, config):
        self.config = config
        self.alert_thresholds = {
            'error_rate_critical': 0.1,      # 10%é”™è¯¯ç‡
            'response_time_critical': 10.0,   # 10ç§’å“åº”æ—¶é—´
            'memory_usage_critical': 0.9,     # 90%å†…å­˜ä½¿ç”¨ç‡
        }
    
    def handle_webhook_alert(self, alert_data):
        """å¤„ç†Webhookå‘Šè­¦"""
        try:
            alerts = alert_data.get('alerts', [])
            
            for alert in alerts:
                alert_name = alert.get('labels', {}).get('alertname')
                severity = alert.get('labels', {}).get('severity')
                status = alert.get('status')  # firing or resolved
                
                # è®°å½•å‘Šè­¦åˆ°æ—¥å¿—
                structured_logger.log_application_event(
                    event_type='alert_received',
                    message=f'Alert {alert_name} is {status}',
                    alert_name=alert_name,
                    severity=severity,
                    status=status,
                    labels=alert.get('labels', {}),
                    annotations=alert.get('annotations', {})
                )
                
                # æ ¹æ®å‘Šè­¦ç±»å‹æ‰§è¡Œç›¸åº”å¤„ç†
                if status == 'firing':
                    self._handle_firing_alert(alert)
                elif status == 'resolved':
                    self._handle_resolved_alert(alert)
            
            return {'status': 'success', 'processed': len(alerts)}
            
        except Exception as e:
            structured_logger.log_error(
                error=e,
                context={'alert_data': alert_data}
            )
            return {'status': 'error', 'message': str(e)}
    
    def _handle_firing_alert(self, alert):
        """å¤„ç†è§¦å‘çš„å‘Šè­¦"""
        alert_name = alert.get('labels', {}).get('alertname')
        severity = alert.get('labels', {}).get('severity')
        
        # ä¸¥é‡å‘Šè­¦ç«‹å³å¤„ç†
        if severity == 'critical':
            self._handle_critical_alert(alert)
        
        # ç‰¹å®šå‘Šè­¦çš„è‡ªåŠ¨åŒ–å¤„ç†
        if alert_name == 'HighMemoryUsage':
            self._handle_memory_alert(alert)
        elif alert_name == 'DatabaseConnectionIssue':
            self._handle_database_alert(alert)
        elif alert_name == 'SecurityEventSpike':
            self._handle_security_alert(alert)
    
    def _handle_critical_alert(self, alert):
        """å¤„ç†ä¸¥é‡å‘Šè­¦"""
        # å‘é€ç´§æ€¥é€šçŸ¥
        self._send_urgent_notification(alert)
        
        # è‡ªåŠ¨æ‰§è¡Œåº”æ€¥æªæ–½
        alert_name = alert.get('labels', {}).get('alertname')
        if alert_name == 'ServiceDown':
            self._attempt_service_restart()
        elif alert_name == 'DiskSpaceAlert':
            self._cleanup_old_logs()
    
    def _handle_memory_alert(self, alert):
        """å¤„ç†å†…å­˜å‘Šè­¦"""
        # è®°å½•å½“å‰ç³»ç»ŸçŠ¶æ€
        import psutil
        memory_info = psutil.virtual_memory()
        
        structured_logger.log_application_event(
            event_type='memory_alert_analysis',
            message='Analyzing memory usage',
            memory_total=memory_info.total,
            memory_used=memory_info.used,
            memory_percent=memory_info.percent,
            memory_available=memory_info.available
        )
        
        # å¦‚æœå†…å­˜ä½¿ç”¨ç‡è¶…è¿‡95%ï¼Œå°è¯•é‡Šæ”¾ç¼“å­˜
        if memory_info.percent > 95:
            self._clear_application_cache()
    
    def _handle_database_alert(self, alert):
        """å¤„ç†æ•°æ®åº“å‘Šè­¦"""
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥æ± çŠ¶æ€
        try:
            from sqlalchemy import inspect
            engine = db.engine
            pool = engine.pool
            
            structured_logger.log_application_event(
                event_type='database_alert_analysis',
                message='Analyzing database connection pool',
                pool_size=pool.size(),
                checked_in=pool.checkedin(),
                checked_out=pool.checkedout(),
                overflow=pool.overflow(),
                invalidated=pool.invalidated()
            )
            
        except Exception as e:
            structured_logger.log_error(
                error=e,
                context={'alert_type': 'database_analysis'}
            )
    
    def _handle_security_alert(self, alert):
        """å¤„ç†å®‰å…¨å‘Šè­¦"""
        # ç«‹å³é€šçŸ¥å®‰å…¨å›¢é˜Ÿ
        self._send_security_notification(alert)
        
        # è®°å½•å®‰å…¨äº‹ä»¶
        structured_logger.log_security_event(
            event_type='security_alert_triggered',
            severity='CRITICAL',
            details={
                'alert': alert,
                'timestamp': datetime.utcnow().isoformat(),
                'auto_response': True
            }
        )
        
        # å¯èƒ½çš„è‡ªåŠ¨å“åº”æªæ–½
        # 1. ä¸´æ—¶å°ç¦å¯ç–‘IP
        # 2. å¢å¼ºæ—¥å¿—è®°å½•
        # 3. é€šçŸ¥ç›¸å…³äººå‘˜
    
    def _send_urgent_notification(self, alert):
        """å‘é€ç´§æ€¥é€šçŸ¥"""
        try:
            # é’‰é’‰/ä¼ä¸šå¾®ä¿¡Webhooké€šçŸ¥
            webhook_url = self.config.get('urgent_webhook_url')
            if webhook_url:
                payload = {
                    "msgtype": "text",
                    "text": {
                        "content": f"ğŸš¨ ä¸¥é‡å‘Šè­¦\n"
                                 f"å‘Šè­¦: {alert.get('annotations', {}).get('summary', 'æœªçŸ¥')}\n"
                                 f"æè¿°: {alert.get('annotations', {}).get('description', 'æ— ')}\n"
                                 f"æ—¶é—´: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\n"
                                 f"è¯·ç«‹å³å¤„ç†ï¼"
                    }
                }
                
                response = requests.post(webhook_url, json=payload, timeout=10)
                response.raise_for_status()
                
        except Exception as e:
            structured_logger.log_error(
                error=e,
                context={'action': 'send_urgent_notification'}
            )
    
    def _attempt_service_restart(self):
        """å°è¯•æœåŠ¡é‡å¯"""
        try:
            import subprocess
            
            # è®°å½•é‡å¯å°è¯•
            structured_logger.log_application_event(
                event_type='auto_service_restart',
                message='Attempting automatic service restart'
            )
            
            # æ‰§è¡Œé‡å¯å‘½ä»¤ï¼ˆéœ€è¦é€‚å½“çš„æƒé™é…ç½®ï¼‰
            result = subprocess.run(
                ['systemctl', 'restart', 'evaluation-system'],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                structured_logger.log_application_event(
                    event_type='auto_restart_success',
                    message='Service restart successful'
                )
            else:
                structured_logger.log_application_event(
                    event_type='auto_restart_failed',
                    message='Service restart failed',
                    error_output=result.stderr
                )
                
        except Exception as e:
            structured_logger.log_error(
                error=e,
                context={'action': 'auto_service_restart'}
            )
    
    def _cleanup_old_logs(self):
        """æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶"""
        try:
            import os
            import glob
            from datetime import datetime, timedelta
            
            log_dir = '/var/log/evaluation-system'
            cutoff_date = datetime.now() - timedelta(days=7)
            
            # æŸ¥æ‰¾7å¤©å‰çš„æ—¥å¿—æ–‡ä»¶
            old_files = []
            for pattern in ['*.log.*', '*.log.gz']:
                files = glob.glob(os.path.join(log_dir, pattern))
                for file_path in files:
                    file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                    if file_time < cutoff_date:
                        old_files.append(file_path)
            
            # åˆ é™¤æ—§æ–‡ä»¶
            deleted_count = 0
            freed_space = 0
            
            for file_path in old_files:
                try:
                    file_size = os.path.getsize(file_path)
                    os.remove(file_path)
                    deleted_count += 1
                    freed_space += file_size
                except OSError:
                    continue
            
            structured_logger.log_application_event(
                event_type='log_cleanup_completed',
                message=f'Cleaned up {deleted_count} old log files',
                deleted_files=deleted_count,
                freed_space_mb=freed_space / (1024 * 1024)
            )
            
        except Exception as e:
            structured_logger.log_error(
                error=e,
                context={'action': 'cleanup_old_logs'}
            )

# Flaskè·¯ç”±å¤„ç†å‘Šè­¦Webhook
alert_handler = AlertHandler(app.config)

@app.route('/webhook/alerts', methods=['POST'])
def handle_alerts():
    """å¤„ç†AlertManagerçš„Webhook"""
    try:
        alert_data = request.get_json()
        result = alert_handler.handle_webhook_alert(alert_data)
        return jsonify(result)
    except Exception as e:
        structured_logger.log_error(error=e)
        return jsonify({'status': 'error', 'message': str(e)}), 500
```

## 5. é“¾è·¯è¿½è¸ªè®¾è®¡

### 5.1 OpenTelemetryé›†æˆ

#### 5.1.1 é“¾è·¯è¿½è¸ªé…ç½®

```python
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

class TracingSetup:
    """é“¾è·¯è¿½è¸ªè®¾ç½®"""
    
    def __init__(self, service_name="evaluation-system", jaeger_host="localhost", jaeger_port=14268):
        self.service_name = service_name
        self.jaeger_host = jaeger_host
        self.jaeger_port = jaeger_port
        self.setup_tracing()
    
    def setup_tracing(self):
        """è®¾ç½®é“¾è·¯è¿½è¸ª"""
        # è®¾ç½®TracerProvider
        trace.set_tracer_provider(TracerProvider())
        tracer = trace.get_tracer(__name__)
        
        # é…ç½®Jaegerå¯¼å‡ºå™¨
        jaeger_exporter = JaegerExporter(
            agent_host_name=self.jaeger_host,
            agent_port=self.jaeger_port,
        )
        
        # è®¾ç½®æ‰¹å¤„ç†Spanå¤„ç†å™¨
        span_processor = BatchSpanProcessor(jaeger_exporter)
        trace.get_tracer_provider().add_span_processor(span_processor)
        
        return tracer
    
    def instrument_app(self, app, db):
        """è‡ªåŠ¨ä»ªè¡¨åŒ–åº”ç”¨"""
        # Flaskè‡ªåŠ¨ä»ªè¡¨åŒ–
        FlaskInstrumentor().instrument_app(app)
        
        # æ•°æ®åº“è‡ªåŠ¨ä»ªè¡¨åŒ–
        SQLAlchemyInstrumentor().instrument(engine=db.engine)
        
        # HTTPè¯·æ±‚è‡ªåŠ¨ä»ªè¡¨åŒ–
        RequestsInstrumentor().instrument()

# è‡ªå®šä¹‰è¿½è¸ªè£…é¥°å™¨
def trace_function(operation_name=None):
    """å‡½æ•°è¿½è¸ªè£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            tracer = trace.get_tracer(__name__)
            span_name = operation_name or f"{func.__module__}.{func.__name__}"
            
            with tracer.start_as_current_span(span_name) as span:
                # æ·»åŠ å‡½æ•°å‚æ•°ä½œä¸ºå±æ€§
                span.set_attribute("function.name", func.__name__)
                span.set_attribute("function.module", func.__module__)
                
                try:
                    result = func(*args, **kwargs)
                    span.set_attribute("function.result", "success")
                    return result
                except Exception as e:
                    span.set_attribute("function.result", "error")
                    span.set_attribute("error.type", type(e).__name__)
                    span.set_attribute("error.message", str(e))
                    raise
        return wrapper
    return decorator

# ä¸šåŠ¡æ“ä½œè¿½è¸ª
@trace_function("evaluation.create")
def create_evaluation_traced(activity_id, vehicle_id, evaluator_id, category_id, score, content):
    """å¸¦è¿½è¸ªçš„è¯„ä»·åˆ›å»ºå‡½æ•°"""
    tracer = trace.get_tracer(__name__)
    
    with tracer.start_as_current_span("evaluation.validate") as validate_span:
        # éªŒè¯å‚æ•°
        validate_span.set_attribute("activity_id", activity_id)
        validate_span.set_attribute("vehicle_id", vehicle_id)
        validate_span.set_attribute("score", score)
        
        if not (1 <= score <= 10):
            validate_span.set_attribute("validation.result", "failed")
            raise ValueError("Score must be between 1 and 10")
        validate_span.set_attribute("validation.result", "success")
    
    with tracer.start_as_current_span("evaluation.database_insert") as db_span:
        # æ•°æ®åº“æ“ä½œ
        evaluation = Evaluation(
            activity_id=activity_id,
            vehicle_id=vehicle_id,
            evaluator_id=evaluator_id,
            category_id=category_id,
            score=score,
            content=content
        )
        
        db.session.add(evaluation)
        db.session.commit()
        
        db_span.set_attribute("evaluation.id", evaluation.id)
        db_span.set_attribute("database.operation", "insert")
        db_span.set_attribute("database.table", "evaluation")
    
    with tracer.start_as_current_span("evaluation.post_process"):
        # åå¤„ç†æ“ä½œ
        metrics_collector.record_evaluation_created(
            category=category_id,
            activity_id=activity_id,
            score=score
        )
        
        structured_logger.log_audit_event(
            action='CREATE',
            resource_type='evaluation',
            resource_id=evaluation.id,
            new_values={
                'activity_id': activity_id,
                'vehicle_id': vehicle_id,
                'evaluator_id': evaluator_id,
                'score': score
            }
        )
    
    return evaluation
```

### 5.2 åˆ†å¸ƒå¼è¿½è¸ªä¸Šä¸‹æ–‡

#### 5.2.1 è¯·æ±‚ä¸Šä¸‹æ–‡ä¼ æ’­

```python
from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
from opentelemetry.baggage.propagation import W3CBaggagePropagator
from opentelemetry.propagators.composite import CompositeHTTPPropagator

class RequestContextManager:
    """è¯·æ±‚ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.propagator = CompositeHTTPPropagator([
            TraceContextTextMapPropagator(),
            W3CBaggagePropagator()
        ])
    
    def extract_context(self, headers):
        """ä»HTTPå¤´ä¸­æå–è¿½è¸ªä¸Šä¸‹æ–‡"""
        return self.propagator.extract(headers)
    
    def inject_context(self, headers, context=None):
        """å°†è¿½è¸ªä¸Šä¸‹æ–‡æ³¨å…¥HTTPå¤´"""
        self.propagator.inject(headers, context)
        return headers

# Flaskä¸­é—´ä»¶é›†æˆ
def setup_tracing_middleware(app):
    """è®¾ç½®è¿½è¸ªä¸­é—´ä»¶"""
    context_manager = RequestContextManager()
    
    @app.before_request
    def extract_trace_context():
        """æå–è¯·æ±‚çš„è¿½è¸ªä¸Šä¸‹æ–‡"""
        context = context_manager.extract_context(dict(request.headers))
        g.trace_context = context
    
    @app.after_request
    def inject_trace_headers(response):
        """æ³¨å…¥è¿½è¸ªå¤´åˆ°å“åº”"""
        headers = {}
        context_manager.inject_context(headers)
        
        for key, value in headers.items():
            response.headers[key] = value
        
        return response

# è‡ªå®šä¹‰Spanå±æ€§
def add_business_attributes(span, **attributes):
    """æ·»åŠ ä¸šåŠ¡ç›¸å…³çš„Spanå±æ€§"""
    for key, value in attributes.items():
        if value is not None:
            span.set_attribute(f"business.{key}", str(value))

# ä½¿ç”¨ç¤ºä¾‹
@app.route('/api/evaluations', methods=['POST'])
@trace_function("api.create_evaluation")
def create_evaluation_api():
    tracer = trace.get_tracer(__name__)
    current_span = trace.get_current_span()
    
    # æ·»åŠ ä¸šåŠ¡å±æ€§
    add_business_attributes(
        current_span,
        user_id=g.get('user_id'),
        operation='create_evaluation',
        api_version='v1'
    )
    
    try:
        data = request.get_json()
        
        with tracer.start_as_current_span("request.validation"):
            # è¯·æ±‚éªŒè¯
            required_fields = ['activity_id', 'vehicle_id', 'evaluator_id', 'score']
            for field in required_fields:
                if field not in data:
                    raise ValueError(f"Missing required field: {field}")
        
        # åˆ›å»ºè¯„ä»·
        evaluation = create_evaluation_traced(**data)
        
        current_span.set_attribute("evaluation.created.id", evaluation.id)
        current_span.set_attribute("response.status", "success")
        
        return jsonify({
            'success': True,
            'evaluation_id': evaluation.id,
            'trace_id': format(current_span.get_span_context().trace_id, '032x')
        })
        
    except Exception as e:
        current_span.set_attribute("response.status", "error")
        current_span.set_attribute("error.type", type(e).__name__)
        raise
```

## 6. æ—¥å¿—èšåˆå’Œåˆ†æ

### 6.1 ELK Stacké›†æˆ (å¯é€‰)

#### 6.1.1 Logstashé…ç½®

```ruby
# logstash.conf
input {
  file {
    path => "/var/log/evaluation-system/*.log"
    start_position => "beginning"
    codec => "json"
    type => "evaluation-system"
  }
}

filter {
  if [type] == "evaluation-system" {
    # è§£æJSONæ—¥å¿—
    json {
      source => "message"
    }
    
    # æ—¶é—´æˆ³å¤„ç†
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    # ç”¨æˆ·IDå¤„ç†
    if [user_id] {
      mutate {
        add_field => { "user_identifier" => "%{user_id}" }
      }
    }
    
    # é”™è¯¯ç­‰çº§æ ‡å‡†åŒ–
    if [levelname] == "ERROR" or [levelname] == "CRITICAL" {
      mutate {
        add_tag => [ "error" ]
      }
    }
    
    # å®‰å…¨äº‹ä»¶æ ‡è®°
    if [event_type] =~ /^security_/ {
      mutate {
        add_tag => [ "security" ]
        add_field => { "log_category" => "security" }
      }
    }
    
    # æ€§èƒ½æŒ‡æ ‡æ ‡è®°
    if [metric_name] {
      mutate {
        add_tag => [ "metrics" ]
        add_field => { "log_category" => "performance" }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "evaluation-system-%{+YYYY.MM.dd}"
  }
  
  # é”™è¯¯æ—¥å¿—é¢å¤–è¾“å‡ºåˆ°ä¸“é—¨ç´¢å¼•
  if "error" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "evaluation-system-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # å®‰å…¨æ—¥å¿—é¢å¤–è¾“å‡º
  if "security" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "evaluation-system-security-%{+YYYY.MM.dd}"
    }
  }
}
```

#### 6.1.2 Elasticsearchç´¢å¼•æ¨¡æ¿

```json
{
  "index_patterns": ["evaluation-system-*"],
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 1,
      "index.refresh_interval": "5s"
    },
    "mappings": {
      "properties": {
        "timestamp": {
          "type": "date",
          "format": "strict_date_optional_time||epoch_millis"
        },
        "levelname": {
          "type": "keyword"
        },
        "event_type": {
          "type": "keyword"
        },
        "user_id": {
          "type": "keyword"
        },
        "request_id": {
          "type": "keyword"
        },
        "remote_addr": {
          "type": "ip"
        },
        "message": {
          "type": "text",
          "analyzer": "standard"
        },
        "error_type": {
          "type": "keyword"
        },
        "processing_time_ms": {
          "type": "float"
        },
        "metric_name": {
          "type": "keyword"
        },
        "metric_value": {
          "type": "float"
        }
      }
    }
  }
}
```

### 6.2 æ—¥å¿—åˆ†æå’Œå¯è§†åŒ–

#### 6.2.1 Kibanaä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "è¯„ä»·ç³»ç»Ÿæ—¥å¿—åˆ†æ",
    "visualizations": [
      {
        "title": "æ—¥å¿—çº§åˆ«åˆ†å¸ƒ",
        "type": "pie",
        "query": {
          "query": {
            "range": {
              "timestamp": {
                "gte": "now-1h"
              }
            }
          },
          "aggs": {
            "log_levels": {
              "terms": {
                "field": "levelname.keyword"
              }
            }
          }
        }
      },
      {
        "title": "é”™è¯¯è¶‹åŠ¿",
        "type": "line",
        "query": {
          "query": {
            "bool": {
              "must": [
                {
                  "terms": {
                    "levelname.keyword": ["ERROR", "CRITICAL"]
                  }
                },
                {
                  "range": {
                    "timestamp": {
                      "gte": "now-24h"
                    }
                  }
                }
              ]
            }
          },
          "aggs": {
            "errors_over_time": {
              "date_histogram": {
                "field": "timestamp",
                "interval": "1h"
              }
            }
          }
        }
      },
      {
        "title": "å®‰å…¨äº‹ä»¶ç›‘æ§",
        "type": "table",
        "query": {
          "query": {
            "bool": {
              "must": [
                {
                  "exists": {
                    "field": "event_type"
                  }
                },
                {
                  "prefix": {
                    "event_type.keyword": "security_"
                  }
                }
              ]
            }
          },
          "sort": [
            {
              "timestamp": {
                "order": "desc"
              }
            }
          ]
        }
      }
    ]
  }
}
```

## 7. è¿ç»´å·¥å…·å’Œè„šæœ¬

### 7.1 ç›‘æ§è„šæœ¬

#### 7.1.1 å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health_check.sh - ç³»ç»Ÿå¥åº·æ£€æŸ¥è„šæœ¬

LOG_FILE="/var/log/evaluation-system/health_check.log"
ALERT_THRESHOLD_CPU=80
ALERT_THRESHOLD_MEMORY=85
ALERT_THRESHOLD_DISK=90

log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

check_service_status() {
    local service_name="$1"
    if systemctl is-active --quiet "$service_name"; then
        log_message "âœ… $service_name is running"
        return 0
    else
        log_message "âŒ $service_name is not running"
        return 1
    fi
}

check_port() {
    local port="$1"
    local service="$2"
    if netstat -tuln | grep -q ":$port "; then
        log_message "âœ… Port $port ($service) is listening"
        return 0
    else
        log_message "âŒ Port $port ($service) is not listening"
        return 1
    fi
}

check_disk_usage() {
    local mount_point="$1"
    local usage=$(df "$mount_point" | awk 'NR==2 {print int($5)}')
    
    if [ "$usage" -lt "$ALERT_THRESHOLD_DISK" ]; then
        log_message "âœ… Disk usage for $mount_point: ${usage}%"
        return 0
    else
        log_message "âš ï¸  High disk usage for $mount_point: ${usage}%"
        return 1
    fi
}

check_memory_usage() {
    local memory_usage=$(free | awk 'NR==2{printf "%.0f", $3*100/$2}')
    
    if [ "$memory_usage" -lt "$ALERT_THRESHOLD_MEMORY" ]; then
        log_message "âœ… Memory usage: ${memory_usage}%"
        return 0
    else
        log_message "âš ï¸  High memory usage: ${memory_usage}%"
        return 1
    fi
}

check_cpu_usage() {
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print int($2)}' | sed 's/%us,//')
    
    if [ "$cpu_usage" -lt "$ALERT_THRESHOLD_CPU" ]; then
        log_message "âœ… CPU usage: ${cpu_usage}%"
        return 0
    else
        log_message "âš ï¸  High CPU usage: ${cpu_usage}%"
        return 1
    fi
}

check_database() {
    local db_file="/var/www/evaluation-system/data/evaluation.db"
    
    if [ -f "$db_file" ]; then
        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å¯è¯»å†™
        if [ -r "$db_file" ] && [ -w "$db_file" ]; then
            log_message "âœ… Database file is accessible"
            
            # ç®€å•æŸ¥è¯¢æµ‹è¯•
            if sqlite3 "$db_file" "SELECT COUNT(*) FROM user;" > /dev/null 2>&1; then
                log_message "âœ… Database query test passed"
                return 0
            else
                log_message "âŒ Database query test failed"
                return 1
            fi
        else
            log_message "âŒ Database file permission issue"
            return 1
        fi
    else
        log_message "âŒ Database file not found"
        return 1
    fi
}

check_application_endpoint() {
    local endpoint="$1"
    local expected_status="$2"
    
    local status_code=$(curl -s -o /dev/null -w "%{http_code}" "$endpoint" --max-time 10)
    
    if [ "$status_code" = "$expected_status" ]; then
        log_message "âœ… Endpoint $endpoint returned $status_code"
        return 0
    else
        log_message "âŒ Endpoint $endpoint returned $status_code (expected $expected_status)"
        return 1
    fi
}

# ä¸»æ£€æŸ¥æµç¨‹
main() {
    log_message "Starting health check..."
    
    local issues=0
    
    # æ£€æŸ¥ç³»ç»ŸæœåŠ¡
    check_service_status "nginx" || ((issues++))
    check_service_status "evaluation-system" || ((issues++))
    
    # æ£€æŸ¥ç½‘ç»œç«¯å£
    check_port "80" "nginx" || ((issues++))
    check_port "5000" "flask-app" || ((issues++))
    
    # æ£€æŸ¥ç³»ç»Ÿèµ„æº
    check_cpu_usage || ((issues++))
    check_memory_usage || ((issues++))
    check_disk_usage "/" || ((issues++))
    
    # æ£€æŸ¥æ•°æ®åº“
    check_database || ((issues++))
    
    # æ£€æŸ¥åº”ç”¨ç«¯ç‚¹
    check_application_endpoint "http://localhost/" "200" || ((issues++))
    check_application_endpoint "http://localhost/health" "200" || ((issues++))
    
    # æ€»ç»“
    if [ "$issues" -eq 0 ]; then
        log_message "âœ… All health checks passed"
        exit 0
    else
        log_message "âŒ Found $issues issues"
        exit 1
    fi
}

# è¿è¡Œå¥åº·æ£€æŸ¥
main "$@"
```

#### 7.1.2 æ—¥å¿—åˆ†æè„šæœ¬

```python
#!/usr/bin/env python3
# log_analyzer.py - æ—¥å¿—åˆ†æè„šæœ¬

import json
import argparse
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import re
import os

class LogAnalyzer:
    """æ—¥å¿—åˆ†æå™¨"""
    
    def __init__(self, log_dir="/var/log/evaluation-system"):
        self.log_dir = log_dir
        self.reports = {
            'summary': {},
            'errors': [],
            'performance': {},
            'security': [],
            'top_users': [],
            'top_endpoints': []
        }
    
    def analyze_logs(self, hours=24):
        """åˆ†ææŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        log_files = [
            'application.log',
            'error.log',
            'security.log',
            'performance.log'
        ]
        
        total_entries = 0
        
        for log_file in log_files:
            file_path = os.path.join(self.log_dir, log_file)
            if os.path.exists(file_path):
                entries = self._parse_log_file(file_path, cutoff_time)
                total_entries += len(entries)
                self._analyze_entries(entries, log_file)
        
        self.reports['summary']['total_entries'] = total_entries
        self.reports['summary']['analysis_period_hours'] = hours
        self.reports['summary']['analysis_time'] = datetime.now().isoformat()
        
        return self.reports
    
    def _parse_log_file(self, file_path, cutoff_time):
        """è§£ææ—¥å¿—æ–‡ä»¶"""
        entries = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        entry = json.loads(line)
                        entry_time = datetime.fromisoformat(
                            entry.get('timestamp', '').replace('Z', '+00:00')
                        )
                        
                        if entry_time >= cutoff_time:
                            entries.append(entry)
                    except (json.JSONDecodeError, ValueError):
                        # è·³è¿‡æ— æ³•è§£æçš„è¡Œ
                        continue
        
        except FileNotFoundError:
            print(f"Warning: Log file {file_path} not found")
        
        return entries
    
    def _analyze_entries(self, entries, log_type):
        """åˆ†ææ—¥å¿—æ¡ç›®"""
        if log_type == 'error.log':
            self._analyze_errors(entries)
        elif log_type == 'performance.log':
            self._analyze_performance(entries)
        elif log_type == 'security.log':
            self._analyze_security(entries)
        elif log_type == 'application.log':
            self._analyze_application(entries)
    
    def _analyze_errors(self, entries):
        """åˆ†æé”™è¯¯æ—¥å¿—"""
        error_types = Counter()
        error_details = []
        
        for entry in entries:
            error_type = entry.get('error_type', 'Unknown')
            error_types[error_type] += 1
            
            error_details.append({
                'timestamp': entry.get('timestamp'),
                'error_type': error_type,
                'error_message': entry.get('error_message', ''),
                'user_id': entry.get('user_id'),
                'request_url': entry.get('request_url')
            })
        
        self.reports['errors'] = {
            'total_errors': len(entries),
            'error_types': dict(error_types.most_common(10)),
            'recent_errors': error_details[-10:]  # æœ€è¿‘10ä¸ªé”™è¯¯
        }
    
    def _analyze_performance(self, entries):
        """åˆ†ææ€§èƒ½æ—¥å¿—"""
        response_times = []
        slow_requests = []
        endpoint_stats = defaultdict(list)
        
        for entry in entries:
            processing_time = entry.get('processing_time_ms', 0)
            endpoint = entry.get('endpoint', 'unknown')
            
            response_times.append(processing_time)
            endpoint_stats[endpoint].append(processing_time)
            
            if processing_time > 5000:  # æ…¢è¯·æ±‚é˜ˆå€¼5ç§’
                slow_requests.append({
                    'timestamp': entry.get('timestamp'),
                    'endpoint': endpoint,
                    'processing_time_ms': processing_time,
                    'request_url': entry.get('request_url')
                })
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if response_times:
            response_times.sort()
            total_requests = len(response_times)
            
            self.reports['performance'] = {
                'total_requests': total_requests,
                'avg_response_time': sum(response_times) / total_requests,
                'p50_response_time': response_times[int(total_requests * 0.5)],
                'p95_response_time': response_times[int(total_requests * 0.95)],
                'p99_response_time': response_times[int(total_requests * 0.99)],
                'slow_requests_count': len(slow_requests),
                'slow_requests': slow_requests[-5:]  # æœ€è¿‘5ä¸ªæ…¢è¯·æ±‚
            }
            
            # ç«¯ç‚¹æ€§èƒ½ç»Ÿè®¡
            endpoint_performance = {}
            for endpoint, times in endpoint_stats.items():
                if len(times) >= 5:  # è‡³å°‘5ä¸ªè¯·æ±‚æ‰ç»Ÿè®¡
                    endpoint_performance[endpoint] = {
                        'count': len(times),
                        'avg_time': sum(times) / len(times),
                        'max_time': max(times)
                    }
            
            self.reports['performance']['endpoint_stats'] = dict(
                sorted(endpoint_performance.items(), 
                      key=lambda x: x[1]['avg_time'], reverse=True)[:10]
            )
    
    def _analyze_security(self, entries):
        """åˆ†æå®‰å…¨æ—¥å¿—"""
        security_events = Counter()
        critical_events = []
        ip_stats = Counter()
        
        for entry in entries:
            event_type = entry.get('event_type', 'unknown')
            severity = entry.get('severity', 'info')
            remote_addr = entry.get('remote_addr')
            
            security_events[event_type] += 1
            
            if remote_addr:
                ip_stats[remote_addr] += 1
            
            if severity in ['critical', 'error']:
                critical_events.append({
                    'timestamp': entry.get('timestamp'),
                    'event_type': event_type,
                    'severity': severity,
                    'remote_addr': remote_addr,
                    'details': entry.get('details', {})
                })
        
        self.reports['security'] = {
            'total_events': len(entries),
            'event_types': dict(security_events.most_common(10)),
            'critical_events': critical_events[-10:],
            'top_source_ips': dict(ip_stats.most_common(10))
        }
    
    def _analyze_application(self, entries):
        """åˆ†æåº”ç”¨æ—¥å¿—"""
        user_activity = Counter()
        endpoint_usage = Counter()
        
        for entry in entries:
            user_id = entry.get('user_id')
            endpoint = entry.get('endpoint')
            
            if user_id:
                user_activity[user_id] += 1
            
            if endpoint:
                endpoint_usage[endpoint] += 1
        
        self.reports['top_users'] = dict(user_activity.most_common(10))
        self.reports['top_endpoints'] = dict(endpoint_usage.most_common(10))
    
    def generate_report(self, output_file=None):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report_text = f"""
# è¯„ä»·ç³»ç»Ÿæ—¥å¿—åˆ†ææŠ¥å‘Š

## æ¦‚è¦ä¿¡æ¯
- åˆ†ææ—¶é—´èŒƒå›´: {self.reports['summary'].get('analysis_period_hours', 'N/A')} å°æ—¶
- æ€»æ—¥å¿—æ¡ç›®: {self.reports['summary'].get('total_entries', 'N/A')}
- ç”Ÿæˆæ—¶é—´: {self.reports['summary'].get('analysis_time', 'N/A')}

## é”™è¯¯åˆ†æ
- æ€»é”™è¯¯æ•°: {self.reports['errors'].get('total_errors', 0)}
"""
        
        # é”™è¯¯ç±»å‹åˆ†å¸ƒ
        if self.reports['errors'].get('error_types'):
            report_text += "\n### é”™è¯¯ç±»å‹åˆ†å¸ƒ\n"
            for error_type, count in self.reports['errors']['error_types'].items():
                report_text += f"- {error_type}: {count}\n"
        
        # æ€§èƒ½åˆ†æ
        if self.reports['performance']:
            perf = self.reports['performance']
            report_text += f"""
## æ€§èƒ½åˆ†æ
- æ€»è¯·æ±‚æ•°: {perf.get('total_requests', 0)}
- å¹³å‡å“åº”æ—¶é—´: {perf.get('avg_response_time', 0):.2f}ms
- P95å“åº”æ—¶é—´: {perf.get('p95_response_time', 0):.2f}ms
- æ…¢è¯·æ±‚æ•°é‡: {perf.get('slow_requests_count', 0)}
"""
        
        # å®‰å…¨åˆ†æ
        if self.reports['security']:
            sec = self.reports['security']
            report_text += f"""
## å®‰å…¨åˆ†æ
- å®‰å…¨äº‹ä»¶æ€»æ•°: {sec.get('total_events', 0)}
- ä¸¥é‡äº‹ä»¶æ•°: {len(sec.get('critical_events', []))}
"""
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
            print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            print(report_text)
        
        return report_text

def main():
    parser = argparse.ArgumentParser(description='è¯„ä»·ç³»ç»Ÿæ—¥å¿—åˆ†æå·¥å…·')
    parser.add_argument('--hours', type=int, default=24, help='åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰')
    parser.add_argument('--log-dir', default='/var/log/evaluation-system', help='æ—¥å¿—ç›®å½•')
    parser.add_argument('--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    
    args = parser.parse_args()
    
    analyzer = LogAnalyzer(args.log_dir)
    reports = analyzer.analyze_logs(args.hours)
    
    if args.json:
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(reports, f, indent=2, ensure_ascii=False)
        else:
            print(json.dumps(reports, indent=2, ensure_ascii=False))
    else:
        analyzer.generate_report(args.output)

if __name__ == '__main__':
    main()
```

## 8. æ€»ç»“

### 8.1 ç›‘æ§ä½“ç³»ä¼˜åŠ¿

1. **å…¨é¢è¦†ç›–**: åº”ç”¨ã€ç³»ç»Ÿã€ä¸šåŠ¡ã€å®‰å…¨ç­‰å¤šç»´åº¦ç›‘æ§
2. **å®æ—¶æ€§**: å®æ—¶æ•°æ®é‡‡é›†å’Œå‘Šè­¦æœºåˆ¶
3. **è‡ªåŠ¨åŒ–**: è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹å’Œå“åº”
4. **å¯æ‰©å±•**: æ”¯æŒç›‘æ§æŒ‡æ ‡å’Œå‘Šè­¦è§„åˆ™æ‰©å±•
5. **æ ‡å‡†åŒ–**: ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼å’Œç›‘æ§æ ‡å‡†

### 8.2 è¿ç»´æ”¯æ’‘èƒ½åŠ›

- **æ•…éšœå¿«é€Ÿå®šä½**: é€šè¿‡æ—¥å¿—å’Œé“¾è·¯è¿½è¸ªå¿«é€Ÿå®šä½é—®é¢˜
- **æ€§èƒ½ä¼˜åŒ–æŒ‡å¯¼**: è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡åˆ†æ
- **å®‰å…¨å¨èƒè¯†åˆ«**: å®æ—¶å®‰å…¨äº‹ä»¶ç›‘æ§å’Œå‘Šè­¦
- **å®¹é‡è§„åˆ’æ”¯æŒ**: èµ„æºä½¿ç”¨è¶‹åŠ¿åˆ†æ
- **ä¸šåŠ¡æ´å¯Ÿ**: ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§å’Œåˆ†æ

### 8.3 æŒç»­æ”¹è¿›è®¡åˆ’

**çŸ­æœŸæ”¹è¿›**:
- å®Œå–„å‘Šè­¦è§„åˆ™å’Œé˜ˆå€¼è°ƒä¼˜
- å¢åŠ æ›´å¤šè‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡
- ä¼˜åŒ–æ—¥å¿—å­˜å‚¨å’Œæ£€ç´¢æ€§èƒ½

**ä¸­æœŸæ”¹è¿›**:
- é›†æˆæœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹
- å®ç°æ™ºèƒ½å‘Šè­¦é™å™ª
- å»ºè®¾å®Œæ•´çš„å¯è§‚æµ‹æ€§å¹³å°

**é•¿æœŸè§„åˆ’**:
- å®ç°AIOpsæ™ºèƒ½è¿ç»´
- å»ºè®¾é¢„æµ‹æ€§è¿ç»´èƒ½åŠ›
- é›†æˆä¸šåŠ¡ç›‘æ§å’ŒæŠ€æœ¯ç›‘æ§

---
**æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆ  
**æœ€åæ›´æ–°**: 2025å¹´7æœˆ23æ—¥  
**ç‰ˆæœ¬å·**: 1.0